\documentclass[]{book}
\usepackage{lmodern}
\usepackage{amssymb,amsmath}
\usepackage{ifxetex,ifluatex}
\usepackage{fixltx2e} % provides \textsubscript
\ifnum 0\ifxetex 1\fi\ifluatex 1\fi=0 % if pdftex
  \usepackage[T1]{fontenc}
  \usepackage[utf8]{inputenc}
\else % if luatex or xelatex
  \ifxetex
    \usepackage{mathspec}
  \else
    \usepackage{fontspec}
  \fi
  \defaultfontfeatures{Ligatures=TeX,Scale=MatchLowercase}
\fi
% use upquote if available, for straight quotes in verbatim environments
\IfFileExists{upquote.sty}{\usepackage{upquote}}{}
% use microtype if available
\IfFileExists{microtype.sty}{%
\usepackage{microtype}
\UseMicrotypeSet[protrusion]{basicmath} % disable protrusion for tt fonts
}{}
\usepackage[margin=1in]{geometry}
\usepackage{hyperref}
\hypersetup{unicode=true,
            pdftitle={Sociospatial Data Science},
            pdfauthor={Christopher Prener, Ph.D.},
            pdfborder={0 0 0},
            breaklinks=true}
\urlstyle{same}  % don't use monospace font for urls
\usepackage{natbib}
\bibliographystyle{apalike}
\usepackage{color}
\usepackage{fancyvrb}
\newcommand{\VerbBar}{|}
\newcommand{\VERB}{\Verb[commandchars=\\\{\}]}
\DefineVerbatimEnvironment{Highlighting}{Verbatim}{commandchars=\\\{\}}
% Add ',fontsize=\small' for more characters per line
\usepackage{framed}
\definecolor{shadecolor}{RGB}{248,248,248}
\newenvironment{Shaded}{\begin{snugshade}}{\end{snugshade}}
\newcommand{\KeywordTok}[1]{\textcolor[rgb]{0.13,0.29,0.53}{\textbf{#1}}}
\newcommand{\DataTypeTok}[1]{\textcolor[rgb]{0.13,0.29,0.53}{#1}}
\newcommand{\DecValTok}[1]{\textcolor[rgb]{0.00,0.00,0.81}{#1}}
\newcommand{\BaseNTok}[1]{\textcolor[rgb]{0.00,0.00,0.81}{#1}}
\newcommand{\FloatTok}[1]{\textcolor[rgb]{0.00,0.00,0.81}{#1}}
\newcommand{\ConstantTok}[1]{\textcolor[rgb]{0.00,0.00,0.00}{#1}}
\newcommand{\CharTok}[1]{\textcolor[rgb]{0.31,0.60,0.02}{#1}}
\newcommand{\SpecialCharTok}[1]{\textcolor[rgb]{0.00,0.00,0.00}{#1}}
\newcommand{\StringTok}[1]{\textcolor[rgb]{0.31,0.60,0.02}{#1}}
\newcommand{\VerbatimStringTok}[1]{\textcolor[rgb]{0.31,0.60,0.02}{#1}}
\newcommand{\SpecialStringTok}[1]{\textcolor[rgb]{0.31,0.60,0.02}{#1}}
\newcommand{\ImportTok}[1]{#1}
\newcommand{\CommentTok}[1]{\textcolor[rgb]{0.56,0.35,0.01}{\textit{#1}}}
\newcommand{\DocumentationTok}[1]{\textcolor[rgb]{0.56,0.35,0.01}{\textbf{\textit{#1}}}}
\newcommand{\AnnotationTok}[1]{\textcolor[rgb]{0.56,0.35,0.01}{\textbf{\textit{#1}}}}
\newcommand{\CommentVarTok}[1]{\textcolor[rgb]{0.56,0.35,0.01}{\textbf{\textit{#1}}}}
\newcommand{\OtherTok}[1]{\textcolor[rgb]{0.56,0.35,0.01}{#1}}
\newcommand{\FunctionTok}[1]{\textcolor[rgb]{0.00,0.00,0.00}{#1}}
\newcommand{\VariableTok}[1]{\textcolor[rgb]{0.00,0.00,0.00}{#1}}
\newcommand{\ControlFlowTok}[1]{\textcolor[rgb]{0.13,0.29,0.53}{\textbf{#1}}}
\newcommand{\OperatorTok}[1]{\textcolor[rgb]{0.81,0.36,0.00}{\textbf{#1}}}
\newcommand{\BuiltInTok}[1]{#1}
\newcommand{\ExtensionTok}[1]{#1}
\newcommand{\PreprocessorTok}[1]{\textcolor[rgb]{0.56,0.35,0.01}{\textit{#1}}}
\newcommand{\AttributeTok}[1]{\textcolor[rgb]{0.77,0.63,0.00}{#1}}
\newcommand{\RegionMarkerTok}[1]{#1}
\newcommand{\InformationTok}[1]{\textcolor[rgb]{0.56,0.35,0.01}{\textbf{\textit{#1}}}}
\newcommand{\WarningTok}[1]{\textcolor[rgb]{0.56,0.35,0.01}{\textbf{\textit{#1}}}}
\newcommand{\AlertTok}[1]{\textcolor[rgb]{0.94,0.16,0.16}{#1}}
\newcommand{\ErrorTok}[1]{\textcolor[rgb]{0.64,0.00,0.00}{\textbf{#1}}}
\newcommand{\NormalTok}[1]{#1}
\usepackage{longtable,booktabs}
\usepackage{graphicx,grffile}
\makeatletter
\def\maxwidth{\ifdim\Gin@nat@width>\linewidth\linewidth\else\Gin@nat@width\fi}
\def\maxheight{\ifdim\Gin@nat@height>\textheight\textheight\else\Gin@nat@height\fi}
\makeatother
% Scale images if necessary, so that they will not overflow the page
% margins by default, and it is still possible to overwrite the defaults
% using explicit options in \includegraphics[width, height, ...]{}
\setkeys{Gin}{width=\maxwidth,height=\maxheight,keepaspectratio}
\usepackage[normalem]{ulem}
% avoid problems with \sout in headers with hyperref:
\pdfstringdefDisableCommands{\renewcommand{\sout}{}}
\IfFileExists{parskip.sty}{%
\usepackage{parskip}
}{% else
\setlength{\parindent}{0pt}
\setlength{\parskip}{6pt plus 2pt minus 1pt}
}
\setlength{\emergencystretch}{3em}  % prevent overfull lines
\providecommand{\tightlist}{%
  \setlength{\itemsep}{0pt}\setlength{\parskip}{0pt}}
\setcounter{secnumdepth}{5}
% Redefines (sub)paragraphs to behave more like sections
\ifx\paragraph\undefined\else
\let\oldparagraph\paragraph
\renewcommand{\paragraph}[1]{\oldparagraph{#1}\mbox{}}
\fi
\ifx\subparagraph\undefined\else
\let\oldsubparagraph\subparagraph
\renewcommand{\subparagraph}[1]{\oldsubparagraph{#1}\mbox{}}
\fi

%%% Use protect on footnotes to avoid problems with footnotes in titles
\let\rmarkdownfootnote\footnote%
\def\footnote{\protect\rmarkdownfootnote}

%%% Change title format to be more compact
\usepackage{titling}

% Create subtitle command for use in maketitle
\newcommand{\subtitle}[1]{
  \posttitle{
    \begin{center}\large#1\end{center}
    }
}

\setlength{\droptitle}{-2em}
  \title{Sociospatial Data Science}
  \pretitle{\vspace{\droptitle}\centering\huge}
  \posttitle{\par}
  \author{Christopher Prener, Ph.D.}
  \preauthor{\centering\large\emph}
  \postauthor{\par}
  \predate{\centering\large\emph}
  \postdate{\par}
  \date{2018-01-05}

\usepackage{booktabs}
\usepackage{amsthm}
\makeatletter
\def\thm@space@setup{%
  \thm@preskip=8pt plus 2pt minus 4pt
  \thm@postskip=\thm@preskip
}
\makeatother

\newenvironment{rmdblock}[1]
  {\begin{shaded*}
  \begin{itemize}
  \renewcommand{\labelitemi}{
    \raisebox{-.7\height}[0pt][0pt]{
      {\setkeys{Gin}{width=3em,keepaspectratio}\includegraphics{images/#1}}
    }
  }
  \item
  }
  {
  \end{itemize}
  \end{shaded*}
  }
\newenvironment{rmdnote}
  {\begin{rmdblock}{note}}
  {\end{rmdblock}}
\newenvironment{rmdtip}
  {\begin{rmdblock}{tip}}
  {\end{rmdblock}}
\newenvironment{rmdwarning}
  {\begin{rmdblock}{warning}}
  {\end{rmdblock}}

\usepackage{amsthm}
\newtheorem{theorem}{Theorem}[chapter]
\newtheorem{lemma}{Lemma}[chapter]
\theoremstyle{definition}
\newtheorem{definition}{Definition}[chapter]
\newtheorem{corollary}{Corollary}[chapter]
\newtheorem{proposition}{Proposition}[chapter]
\theoremstyle{definition}
\newtheorem{example}{Example}[chapter]
\theoremstyle{definition}
\newtheorem{exercise}{Exercise}[chapter]
\theoremstyle{remark}
\newtheorem*{remark}{Remark}
\newtheorem*{solution}{Solution}
\begin{document}
\maketitle

{
\setcounter{tocdepth}{1}
\tableofcontents
}
\hypertarget{preface}{\chapter*{Preface}\label{preface}}
\addcontentsline{toc}{chapter}{Preface}

\begin{center}\includegraphics[width=0.4\linewidth]{images/SSDSBookBanner} \end{center}

This text is a companion text for both of my research methods courses at
\href{https://slu.edu}{Saint Louis University}:

\begin{itemize}
\tightlist
\item
  \href{https://slu-soc5650.github.io}{SOC 4650/5650 - Introduction to
  Geographic Information Science}
\item
  \href{https://slu-soc5050.github.io}{SOC 4930/5050 - Quantitative
  Analysis: Applied Inferential Statistics}
\end{itemize}

The goal of the text is to create a reference for the intangible, subtle
or disparate skills and ideas that contribute to being a successful
\emph{computational} social scientist. In writing this text, I draw
inspiration from the work of Donald Knuth.\footnote{\href{https://en.wikipedia.org/wiki/Donald_Knuth}{Donald
  Knuth} is the developer of
  \href{https://en.wikipedia.org/wiki/TeX}{TeX}, a computer typesetting
  system that is widely used today for scientific publishing in the form
  of \href{https://en.wikipedia.org/wiki/LaTeX}{LaTeX}. He also
  established the concept of
  \href{https://en.wikipedia.org/wiki/Literate_programming}{literate
  programming}, which forms the basis of some of the practices we follow
  with \texttt{R}.} Knuth has discussed his experiences in designing new
software languages, nothing that the developer of a new language

\begin{quote}
\ldots{}must not only be the implementer and the first large-scale user;
the designer should also write the first user manual\ldots{} If I had
not participated fully in all these activities, literally hundreds of
improvements would never have been made, because I would never have
thought of them or perceived why they were important\ldots{}
\end{quote}

While there is nothing particularly new about what I am writing here,
and I am certainly not developing a new language for computing, the goal
of this text remains similar to Knuth's experience. By distilling some
of key elements for making a successful transition to being a
\emph{professional developer} of knowledge rather than a \emph{casual
consumer}, I hope to both improve the course experience itself and also
create an environment that fosters a successful learning experience for
you.

In both classes, the course names are deceptive. We are not only
concerned with statistical work or mapping. Rather, we are more
fundamentally concerned with research methods. In particular, we are
concerned with \emph{high quality} research methods and the
\emph{process} of conducting research. We therefore focus on a
combination of mental habits and technical practices that make you a
successful researcher. Some of the skills and techniques that we will
discuss this semester are not taught as often in graduate programs, let
along undergraduate programs. Instead, they are often the products of
``learning the hard way''. These ``habits of mind and habits of method''
are broadly applicable across methodologies and disciplines.

\section*{License}\label{license}
\addcontentsline{toc}{section}{License}

Copyright Â© 2016-2018 \href{https://chris-prener.github.io}{Christopher
G. Prener}

This work is licensed under a Creative Commons Attribution-ShareAlike
4.0 International License.

\hypertarget{intro}{\chapter{Introduction}\label{intro}}

The first part of this text is designed to help get you oriented to
coursework in computational social science. Both
\href{https://slu-soc5650.github.io}{Introduction to Geographic
Information Science (SOC 4650/5650)} and
\href{https://slu-soc5050.github.io}{Quantitative Analysis: Applied
Inferential Statistics (SOC 4930/5050)} are focused on building
students' capacities to address social science research questions using
tools that have been the traditional domain of computer and information
scientists. The growth and application of these tools in a variety of
disciplines both inside and outside of the social sciences has come to
be known as data science. Both courses are taught from this perspective,
so that while we focus on social science data, the tools and techniques
are broadly applicable across disciplines.

\section{Opinionated Processes}\label{opinionated-processes}

This text, and both of the courses it is written with an eye towards, is
meant to be ``opinionated''. We'll introduce a high level definition of
opinionated process here, and discuss how these ideas might fit into
previous coursework you've taken.

\subsection{Opinionated Analysis
Development}\label{opinionated-analysis-development}

The idea of research being opinionated is something we borrow from
\href{https://twitter.com/hspter}{Hiliary Parker}, who has been
developing the idea of
\href{https://peerj.com/preprints/3210/}{``opinionated analysis
development''} over the last several years. Parker (2017) argues that
opinionated analysis development is a guard against human errors in data
analysis that are common but preventable. She emphasizes process
repeatedly because, in her view, errors in data analysis are often the
result of poor process (and not the individual failures of an analyst).

Following Hilary's lead, we will also make process a cornerstone of our
coursework. This emphasis on process is not routine in research methods
courses (Long 2009), which often treat methods and techniques in
isolation and leave much about how they fit together to be learned ``the
hard way''. A common experience with statistics coursework is that
students will learn the assumptions and requirements of various tests,
but not how to fit them together to produce a well-conceptualized
analysis. Thus, students working on their first research projects often
feel personal responsibility for errors ``despite not being taught
processes that protect against them'' (Parker 2017:2).

Parker (2017) lays out three core areas for analysis development.
Analyses should be (1) reproducible and auditable, (2) accurate, and (3)
collaborative. She also provides a set of opinions and questions about
each of these these categories. Projects that are both reproducible and
auditable, for example, should be driven by executable analysis scripts
with clearly defined dependencies. Projects that are accurate should use
modular, tested code and should assertively test data, assumptions, and
results. Finally, projects that are collaborative should use version
control software for project management, should have the ability to
track issues, and should allow for communications that can be archived
easily.

This text introduces strategies and techniques for implementing these
opinions in data science research, with special emphasis on doing so in
social science and geospatial projects. While these ideas appear in
nearly every chapter, the chapter on
\protect\hyperlink{good-enough-research-practices}{``Good Enough''
Research Practices} pays particular attention to these concepts in
greater detail.

\subsection{Contextualizing These
Ideas}\label{contextualizing-these-ideas}

Each time I teach a research methods course, I have students with a mix
of experiences. For some students, all of these concepts and techniques
are new and they therefore do not have a strong conception of what it
means to do research. For other students, particularly those with
research experience, these ideas can directly conflict with how they
have been taught in the past and how they work. For everyone, these
ideas require a greater mindfulness and attention to detail than they
are used to.

Occasionally, students react strongly to these ideas. For example, these
opinions could be interpreted as an indictment of students' own
processes or seen as a desire to micromanage. Others could see the focus
on process as misplaced. After all, as long as the final product looks
good, what does it matter how organized the analyst's hard drive is (or
isn't)? If you feel like this at any point in the semester, I can
sympathize greatly. I remember the frustration I felt the first time I
was told that I didn't name variables well and that my code was written
in a way that was hard to read.

What I didn't understand at the time, and what I strive to emphasize
now, is that process cannot be separated from product. If the process is
unclear, undefined, or disorganized, our faith in the final product
should be diminished because these flaws limit our ability to judge its
accuracy. Thus being ``right'' is not solely a judgement of the final
results but also how they were obtained. This emphasis on process is
inherently more time consuming, slower, and more deliberate than a
slapdash approach to data analysis. Our goal is not to conduct data
science work in the easiest way, however, it is to conduct it in the
most robust way possible.

\section{What is data science?}\label{what-is-data-science}

Given data science's new emergence, its definition remains both
contested and often unclear. For me, there are four key aspects to focus
on when considering what constitutes data science:

\begin{enumerate}
\def\labelenumi{\arabic{enumi}.}
\tightlist
\item
  Statistics
\item
  Programming
\item
  Visualization and Communication
\item
  Substantive Knowledge
\end{enumerate}

I think of this as a ``full stack'' approach to computational research.
You want to be well versed not only the techniques for generating and
analyzing data, but also substantively in the academic literature about
your area of interest as well as ways to communicate your findings with
other researchers and the wider public.

\subsection{Statistics}\label{statistics}

Statistics covers the mathematical techniques that we use to draw
inference from our data. It is the main subject of one my courses,
\href{https://slu-soc5050.github.io}{Quantitative Analysis}. In
\href{https://slu-soc5650.github.io}{Introduction to GIS}, we do not
explicitly cover much in the way of inferential statistics. However, the
course is designed to prepare you for a next level, Intermediate GIS
course that covers spatial statistics.

\subsection{Programming}\label{programming}

Computer programming is an essential part of data science broadly and
computational social science more specifically. Using a programming
language means that our work can be easily reproduced. This emphasis on
\textbf{reproducibility} is a response to a growing fear in many
disciplines that results are replicable from study to study, which
raises questions about the validity of much of the research work that we
do. Our goal in both courses is to produce research that is as
reproducible as possible.

This book introduces two programming languages -
\href{https://en.wikipedia.org/wiki/R_(programming_language)}{\texttt{R}}
and
\href{https://en.wikipedia.org/wiki/Python_(programming_language)}{Python}.
In \href{https://slu-soc5050.github.io}{Quantitative Analysis}, we will
be focused exclusively on learning \texttt{R} and using it to produce
statistical analyses. In
\href{https://slu-soc5650.github.io}{Introduction to GIS}, we will spend
a lot of time in \texttt{R}, but we will also use some Python to help
pass data from \texttt{R} to ArcGIS, the mapping application we will
use. I will also provide some additional Python lessons to folks who are
interested, but these will not be required for the course.

\subsection{Visualization \&
Communication}\label{visualization-communication}

Visualization is a fundamental aspect of data science work. It is how we
make our results easily digestible and accessible to a wider audience,
many of whom may not be able to interpret statistical output but can
learn from a well-designed scatter plot. In
\href{https://slu-soc5050.github.io}{Quantitative Analysis}, we will
focus on building plots to communicate information about statistical
distributions and the relationships between our variables. In
\href{https://slu-soc5650.github.io}{Introduction to GIS}, we will use
the same fundamental skills to build simple maps in \texttt{R}. We will
extend our emphasis on visualization to ArcGIS, where we will focus on
producing cartographically rich depictions of our data.

Separately, we will discuss the presentation of statistical data in
tables using \href{https://en.wikipedia.org/wiki/LaTeX}{LaTex} in
\href{https://slu-soc5050.github.io}{Quantitative Analysis} as well as
the producing to conference-style presentations to communicate research
findings. In \href{https://slu-soc5650.github.io}{Introduction to GIS},
we will focus on producing conference-style posters instead. These are
different mediums, but they rely on the same design fundamentals that
are covered in this text.

\subsection{Substantive Knowledge}\label{substantive-knowledge}

Substantive knowledge covers two tangentially related topics: the
ability to work well in groups and the ability to digest and integrate
an academic literature into your own research. Each of these topics
receive some focus in both
\href{https://slu-soc5050.github.io}{Quantitative Analysis} and
\href{https://slu-soc5650.github.io}{Introduction to GIS}. Each class
has some group work associated with the completion with weekly lab
assignments. \href{https://slu-soc5650.github.io}{Introduction to GIS}
also has a group work component associated with the final project. In
each class, students' final projects are focused on a specific content
area that requires at least some background research and knowledge.
Synthesizing this knowledge and integrating it into your final projects
is a key piece of addressing this facet of data science.

\section{How is this book organized?}\label{how-is-this-book-organized}

Like many books about data science, this text follows a number of
standard conventions related to how it is organized and how examples are
given. This section introduces those conventions.

\subsection{Typefaces and Fonts}\label{typefaces-and-fonts}

Technical publications that describe scientific computing processes use
a \texttt{monospaced\ typewriter\ style\ typeface} to refer to commands
(inputs) and results (outputs). In some documents, like lecture slides
and cheat-sheets, I may highlight a command by using a particular color
to increase the visibility of the command name itself.

The \texttt{typewriter\ typeface} is also used to refer to functions
(e.g. \texttt{library()}), file names (e.g. \texttt{mpg.csv}) or file
paths (e.g.
\texttt{C:\textbackslash{}Users\textbackslash{}JSmith\textbackslash{}Desktop}).
Finally, we will use the \texttt{typewriter\ typeface} to refer to
GitHub repositories (e.g. \texttt{Core-Documents}, the repository that
contains this file).

Technical publications use \emph{italicized text} to refer to text that
is meant to be replaced. These references will typically appear in a
\texttt{typewriter\ typeface} since they are often part of commands. For
example, \texttt{str(dataFrame)} (with \texttt{dataFrame}
\emph{italicized}) indicates that you should replace the text
\texttt{dataFrame} with the appropriate variable name from your data
set.

These publications also use a sans serif typeface to refer to areas of
the user interface, menu items, and buttons. I cannot replicate that
here because of the publishing software that I use, but you'll notice
this text in course documents. We will therefore use the
\texttt{typewriter\ typeface} in the User Guide to identify these same
features.

Technical documents also use a sans serif or \texttt{typewriter}
typeface to refer to keyboard keys (e.g. \texttt{Crtl+C}) where the plus
sign (\texttt{+}) indicates that you should press multiple keys at the
same time. A sans serif typeface combined with a right facing
triangle-style arrow (\texttt{\textgreater{}}) is used to refer to
actions that require clicking through a hierarchy of menus or windows
(e.g. \texttt{File\ \textgreater{}\ Save}).

\subsection{Data}\label{data}

There are two sets of data that are used in this text, and they are also
used as part of \href{https://slu-soc5050.github.io}{Quantitative
Analysis} and \href{https://slu-soc5650.github.io}{Introduction to GIS}.
Both are available as \texttt{R} packages. The \texttt{testDriveR}
package contains some generic data that are particularly well suited for
exploring statistical topics. The \texttt{stlData} package contains data
that can be mapped at various levels. Both of these packages are
currently available on \href{https://github.com}{GitHub}, and can be
installed using the \texttt{devtools} package:

\begin{Shaded}
\begin{Highlighting}[]
\KeywordTok{install.packages}\NormalTok{(}\StringTok{"devtools"}\NormalTok{)}
\KeywordTok{library}\NormalTok{(devtools)}
\NormalTok{devtools}\OperatorTok{::}\KeywordTok{install_github}\NormalTok{(}\StringTok{"chris-prener/testDriveR"}\NormalTok{)}
\NormalTok{devtools}\OperatorTok{::}\KeywordTok{install_github}\NormalTok{(}\StringTok{"chris-prener/stlData"}\NormalTok{)}
\end{Highlighting}
\end{Shaded}

\subsection{Examples}\label{examples}

Throughout the semester, I will give you examples both in lecture slides
and in an example do-file. Examples in lectures and course documents can
be easily identified by their use of the \texttt{typewriter\ typeface}:

\begin{Shaded}
\begin{Highlighting}[]
\OperatorTok{>}\StringTok{ }\KeywordTok{library}\NormalTok{(stlData)}
\OperatorTok{>}\StringTok{ }\KeywordTok{str}\NormalTok{(stlLead)}
\StringTok{'data.frame'}\OperatorTok{:}\StringTok{   }\DecValTok{106}\NormalTok{ obs. of  }\DecValTok{15}\NormalTok{ variables}\OperatorTok{:}
\StringTok{ }\ErrorTok{$}\StringTok{ }\NormalTok{geoID         }\OperatorTok{:}\StringTok{ }\NormalTok{num  }\FloatTok{2.95e+10} \FloatTok{2.95e+10} \FloatTok{2.95e+10} \FloatTok{2.95e+10} \FloatTok{2.95e+10}\NormalTok{ ...}
 \OperatorTok{$}\StringTok{ }\NormalTok{tractCE       }\OperatorTok{:}\StringTok{ }\NormalTok{int  }\DecValTok{118100} \DecValTok{117400} \DecValTok{126700} \DecValTok{119102} \DecValTok{126800} \DecValTok{126900} \DecValTok{108100} \DecValTok{127000} \DecValTok{127400} \DecValTok{103700}\NormalTok{ ...}
 \OperatorTok{$}\StringTok{ }\NormalTok{nameLSAD      }\OperatorTok{:}\StringTok{ }\NormalTok{chr  }\StringTok{"Census Tract 1181"} \StringTok{"Census Tract 1174"} \StringTok{"Census Tract 1267"} \StringTok{"Census Tract 1191.02"}\NormalTok{ ...}
 \OperatorTok{$}\StringTok{ }\NormalTok{countTested   }\OperatorTok{:}\StringTok{ }\NormalTok{int  }\DecValTok{345} \DecValTok{871} \DecValTok{458} \DecValTok{182} \DecValTok{486} \DecValTok{1296} \DecValTok{903} \DecValTok{585} \DecValTok{2116} \DecValTok{417}\NormalTok{ ...}
 \OperatorTok{$}\StringTok{ }\NormalTok{pctElevated   }\OperatorTok{:}\StringTok{ }\NormalTok{num  }\FloatTok{9.57} \FloatTok{12.06} \FloatTok{18.12} \FloatTok{2.2} \FloatTok{4.73}\NormalTok{ ...}
 \OperatorTok{$}\StringTok{ }\NormalTok{totalPop      }\OperatorTok{:}\StringTok{ }\NormalTok{int  }\DecValTok{1161} \DecValTok{4307} \DecValTok{1089} \DecValTok{3237} \DecValTok{3490} \DecValTok{4590} \DecValTok{3144} \DecValTok{2052} \DecValTok{5486} \DecValTok{2408}\NormalTok{ ...}
 \OperatorTok{$}\StringTok{ }\NormalTok{totalPop_MOE  }\OperatorTok{:}\StringTok{ }\NormalTok{int  }\DecValTok{192} \DecValTok{447} \DecValTok{199} \DecValTok{309} \DecValTok{231} \DecValTok{826} \DecValTok{464} \DecValTok{273} \DecValTok{516} \DecValTok{274}\NormalTok{ ...}
 \OperatorTok{$}\StringTok{ }\NormalTok{white         }\OperatorTok{:}\StringTok{ }\NormalTok{int  }\DecValTok{414} \DecValTok{2604} \DecValTok{432} \DecValTok{2008} \DecValTok{3026} \DecValTok{148} \DecValTok{108} \DecValTok{304} \DecValTok{1777} \DecValTok{2149}\NormalTok{ ...}
 \OperatorTok{$}\StringTok{ }\NormalTok{white_MOE     }\OperatorTok{:}\StringTok{ }\NormalTok{int  }\DecValTok{100} \DecValTok{303} \DecValTok{116} \DecValTok{262} \DecValTok{270} \DecValTok{217} \DecValTok{111} \DecValTok{82} \DecValTok{391} \DecValTok{212}\NormalTok{ ...}
 \OperatorTok{$}\StringTok{ }\NormalTok{black         }\OperatorTok{:}\StringTok{ }\NormalTok{int  }\DecValTok{724} \DecValTok{1338} \DecValTok{631} \DecValTok{646} \DecValTok{194} \DecValTok{4320} \DecValTok{3020} \DecValTok{1739} \DecValTok{3603} \DecValTok{156}\NormalTok{ ...}
 \OperatorTok{$}\StringTok{ }\NormalTok{black_MOE     }\OperatorTok{:}\StringTok{ }\NormalTok{int  }\DecValTok{179} \DecValTok{374} \DecValTok{187} \DecValTok{210} \DecValTok{98} \DecValTok{760} \DecValTok{442} \DecValTok{283} \DecValTok{621} \DecValTok{190}\NormalTok{ ...}
 \OperatorTok{$}\StringTok{ }\NormalTok{povertyTot    }\OperatorTok{:}\StringTok{ }\NormalTok{int  }\DecValTok{324} \DecValTok{615} \DecValTok{506} \DecValTok{958} \DecValTok{349} \DecValTok{1743} \DecValTok{652} \DecValTok{331} \DecValTok{2524} \DecValTok{254}\NormalTok{ ...}
 \OperatorTok{$}\StringTok{ }\NormalTok{povertyTot_MOE}\OperatorTok{:}\StringTok{ }\NormalTok{int  }\DecValTok{140} \DecValTok{255} \DecValTok{164} \DecValTok{234} \DecValTok{129} \DecValTok{825} \DecValTok{305} \DecValTok{156} \DecValTok{598} \DecValTok{88}\NormalTok{ ...}
 \OperatorTok{$}\StringTok{ }\NormalTok{povertyU18    }\OperatorTok{:}\StringTok{ }\NormalTok{int  }\DecValTok{109} \DecValTok{169} \DecValTok{98} \DecValTok{15} \DecValTok{35} \DecValTok{627} \DecValTok{256} \DecValTok{47} \DecValTok{1110} \DecValTok{15}\NormalTok{ ...}
 \OperatorTok{$}\StringTok{ }\NormalTok{povertyU18_MOE}\OperatorTok{:}\StringTok{ }\NormalTok{int  }\DecValTok{105} \DecValTok{156} \DecValTok{60} \DecValTok{25} \DecValTok{47} \DecValTok{595} \DecValTok{136} \DecValTok{79} \DecValTok{318} \DecValTok{23}\NormalTok{ ...}
\end{Highlighting}
\end{Shaded}

Examples will almost always use the data frame \texttt{stlLead}, which
comes with the \texttt{stlData} package. To open it, simply load the
\texttt{stlData} package using the \texttt{library()} function and then
start referencing \texttt{stlLead} anytime you need a data frame. This
allows you to easily recreate examples by minimizing dependencies within
your code.

\part{First Steps}\label{part-first-steps}

\chapter{Approaching These Courses}\label{approaching-these-courses}

Students have varying experiences learning computational techniques. For
some, the math and programming that are the foundation for modern data
science techniques come naturally. For others, being introduced to these
concepts can be an anxiety producing experience. I am fond the phrase
``your mileage will vary'' for describing these differences - no two
students have the exact same experience taking a computational methods
course. Like the previous chapter, some of the content below is specific
to the courses (\href{https://slu-soc5650.github.io}{Introduction to
Geographic Information Science (SOC 4650/5650)} and
\href{https://slu-soc5050.github.io}{Quantitative Analysis: Applied
Inferential Statistics (SOC 4930/5050)}) I teach at
\href{https://www.slu.edu}{Saint Louis University}, the general outlook
on approaching data science work that I describe below is hopefully
applicable in a far wider arena.

\hypertarget{zen-and-the-art-of-data-analysis}{\section{Zen and the Art
of Data Analysis}\label{zen-and-the-art-of-data-analysis}}

One of the biggest challenges with this course can be controlling the
anxiety that comes along with learning new skills. \texttt{R} syntax,
GIS terms, LaTeX commands, and Markdown can seem like foreign alphabets
at first. Debugging \texttt{R} syntax can be both challenging and a
large time suck, in part because you are not yet fluent with this
language. Imagine trying to proofread a document written in a language
that you only know in a cursory way but where you must find minute
inconsistencies like misplaced commas.

For this reason, I also think it is worth reminding you that many
students in the social sciences struggle with computational methods at
first. It is normal to find this challenging and frustrating. I find
that students who can recognize when they are beginning to go around in
circles are often the most successful at managing the issues that will
certainly arise during this course. Recognizing the signs that you are
starting to spin your wheels and taking either ten minutes, an hour or
two, or a day away from computational coursework is often a much better
approach than trying to power through problems.

Data analysis therefore requires a certain mindfulness. I mentioned in
the \protect\hyperlink{preface}{Preface} that much of what this book
covers are ``habits of mind and habits of method''. These mental habits
extend past being able to recognize that frustration is setting in. They
also include the mental habits needed for
\protect\hyperlink{getting-and-staying-organized}{Getting and Staying
Organized} and strategies for \protect\hyperlink{getting-help}{Getting
Help} as you navigate the inevitable errors that come with learning new
analytically skills.

\hypertarget{getting-and-staying-organized}{\section{Getting and Staying
Organized}\label{getting-and-staying-organized}}

Doing data science work, and having the space to step away for a day as
the last section suggests, requires discipline and organization.
Similarly, computational coursework can demanding not just because it is
complex but because the courses often have a number of moving pieces
that you need to keep track of. Being mindful of this challenge from the
beginning, and taking steps to plan for it, is an important part of this
course.

\subsection{Keeping Track of Where You
Are}\label{keeping-track-of-where-you-are}

Students who have some system for tracking their work and creating to-do
lists are often the most successful in this course, not because they
have a fundamentally better grasp on the content but because they simply
are more organized. If you have never thought particularly hard about
how you manage tasks, now is an excellent time to start doing so. You do
not need fancy computer software to accomplish this, though there are an
array of possibilities if you do want to use software to keep yourself
organized. A legal pad or a notebook can be just as effective as a \$50
to-do list manager. The point is, do \emph{something}!

I am fond of recommending the
\href{http://gettingthingsdone.com}{\textbf{Getting Things Done}}
methodology to students as part of thinking more holistically about
staying organized. The website \href{https://lifehacker.com}{Lifehacker}
posted an
\href{https://lifehacker.com/productivity-101-a-primer-to-the-getting-things-done-1551880955}{excellent
introduction to GTD} that is a great way to get a sense of how it works
and find additional resources for implementing it.

The GTD website has a
\href{http://gettingthingsdone.com/common-tools-software/}{great list of
software} for those of you looking for a to-do list application. One
that isn't listed that I use for collaborating with my student research
team is \href{https://trello.com}{Trello}, a freemium website that
allows you to create simple to-do lists. It isn't sophisticated enough
for implementing GTD, but it is more than sufficient for managing to-do
lists related to this course.

\subsection{Managing Course Materials}\label{managing-course-materials}

For both courses covered by this book, materials will be disseminated in
physical and digital form. The topic of keeping digital materials
organized is the subject of the next chapter
\protect\hyperlink{protecting-your-work}{Protecting Your Work}. The
physical handouts and materials that we'll give out will all come three
hole punched, and you are expected to purchase a three-ring binder for
this course. I give out enough handouts that, without a binder, it
becomes difficult to keep track of where handouts are located. I have
watched students spend more time looking for the handout than it takes
to find the answer to their question once they have the handout itself.

There are two recommended ways to keep your binder tidy. One is to
organize by lecture. There are sixteen lectures worth of handouts in
both courses (not including the course preview and the final research
conference session), so two sets of dividers (which often come in packs
of eight) should be sufficient. The other way to organize handouts is by
topic. We hand out a number of different types of documents that could
be organized thematically like so:

\begin{enumerate}
\def\labelenumi{\arabic{enumi}.}
\tightlist
\item
  Syllabus and reading list
\item
  Workflow diagrams
\item
  \texttt{R} function sheets
\item
  ArcGIS process sheets (SOC 4650/5650 only)
\item
  LaTeX command sheets (SOC 4930/5050 only)
\item
  Sample outputs
\item
  Exercise handouts
\item
  Lab handouts
\item
  Problem set handouts
\end{enumerate}

Since there are approximately eight different types of handouts in each
class, a single package of dividers should be sufficient for this
approach to organizing them.

I don't think that one way of organization, thematically or temporally,
is inherently better or worse than the other. In large part it comes
down to how \emph{you} like to organize information. After all, learning
how to process and organize information in a way that works for you is
the most important takeaway here.

\section{Course Flow}\label{course-flow}

\begin{center}\includegraphics[width=1\linewidth]{images/courseWorkflow} \end{center}

Both \href{https://slu-soc5050.github.io}{Quantitative Analysis} and
\href{https://slu-soc5650.github.io}{Introduction to GIS} follow the
same weekly flow or progression. The structure of the assignments and
course materials presupposes that you adhere to this progression.

\subsection{Reading with Purpose}\label{reading-with-purpose}

The book and article \textbf{reading assignments} for this course are
different from most of the other reading you will do in your graduate
program because they are often very technical. Students who are most
successful in this course read twice. Read the first time to expose
yourself to the material, then take a break from the reading. During
this first read, I don't recommend trying to complete the example
problems or programming examples. Focus on the \emph{big picture} - what
are the concepts and ideas that these readings introduce?

During the second read, try to focus in in the \emph{details} - what are
the technical details behind the big picture concepts? I recommend doing
this second read with your computer open. Follow along with the examples
and execute as much of them as you can. By using this second read
through as a way to test the waters and experiment with the week's
content, you can come into the lecture better prepared to take full
advantage of the class period. Students who follow this approach are
able make important connections and focus on the essential details
during lectures because it is their third time being exposed to the
course material. They are also in a much stronger position to ask
questions.

\subsection{Lecture Preps}\label{lecture-preps}

Once you've completed the readings for the week, tackle the
\textbf{lecture prep}. These short assignments are designed to help
prepare you for the upcoming lecture by reviewing some of the concepts
from the reading. For many of the preps, I will post replication videos
on YouTube that show how to solve each problem and provide some
explanation for that process. Use this as an early indication of how
well you understood the readings and what questions you might have.
Bringing these questions to class is a great way to build your knowledge
of the course material.

\subsection{Active Lectures and Labs}\label{active-lectures-and-labs}

During \textbf{lectures}, I introduce many of the same topics that your
readings cover. This again is intentional - it gives you yet another
exposure to concepts and techniques that are central to geospatial
science. One mistake students sometimes make is focusing on the details
of \emph{how} to do a particular task rather than focusing on
\emph{when} a task should be done. If you know when a task is needed but
cannot remember how to do it in \texttt{R}, you can look this
information up. Conversely, detailed notes on executing \texttt{R}
commands may not be helpful if you are unsure when to use a particular
skill. There is no penalty in this course for not knowing how to execute
a command from memory; this is what reference materials are for. The
most successful students will therefore focus on \emph{when} a
particular skill is warranted first before focusing on \emph{how} to
execute that skill

Getting experience with executing tasks is the purpose of the
\textbf{lab exercises}. These are narrowly defined and focused on
building your confidence with the specific skills introduced each week.
Time for beginning these exercises is given at the end of each class
meeting, and replication files will be posted on GitHub for each lab. I
suggest that students do not look at replication files until they are
truly stumped. Spend some time wrestling with problems and code, and
experiment with the trouble shooting process, when the stakes are low
and you have a safety-net to catch you. This will prepare you to respond
to issues on the problem sets in a more resilient way.

\subsection{Problem Sets}\label{problem-sets}

The problem sets are the key evaluation of your progress in the course.
These will cover skills both for the week they are assigned as well as
previous weeks to ensure that you are connecting various aspects of the
course and are able to transition skills from one week to the next.
Replication files will be provided after all problem sets are submitted
and grades are returned. Review these replication files regardless of
how well you do on a given problem set - there is much to learn from
reviewing your progress and seeing a different approach to these
assignments.

\subsection{An Apple a Day}\label{an-apple-a-day}

As I noted above, some degree of frustration with these courses is to be
expected - functions in \texttt{R} will not work as intended, for
example, and the ambiguity of error messages can be excruciating. I
suggested above that you build into your approach to the course time to
walk away from assignments if you hit a wall. Being able to walk away
from an assignment for a day requires excellent time management. If you
are waiting until the night before or the day of an assignment's due day
to begin it, you give yourself little room for errors.

I recommend approaching this course in bite size chunks - a little each
day. The most successful students do not do all of their reading,
homework, and studying in a single sitting. I find that this approach
not only creates unnecessary anxiety around assignments, it also
dramatically limits the amount of course material you can absorb. Keep
in mind that I expect the \emph{median} student to spend approximately
six hours on work for this class each week (twice the amount of in-class
time). A sample approach to the class might look something like this:

\begin{itemize}
\tightlist
\item
  Monday: class
\item
  Tuesday: finish lab
\item
  Wednesday: Start problem set
\item
  Thursday: Finish problem set
\item
  Friday: First reading
\item
  Saturday: Second reading
\item
  Sunday: Lecture prep for next class
\end{itemize}

The single biggest failure point in both courses for students is
thinking that the few hours before class are sufficient for doing
\emph{all} of the work required for a particular week. It is the rare
student who can do this successfully (not only in terms of meeting the
required deadlines but also in terms of actually learning the material).
Err on the side of giving yourself too much time to complete work rather
than just enough!

\section{Staying Current}\label{staying-current}

Course content is maintained both on the respective course websites
(\href{https://slu-soc5050.github.io}{Quantitative Analysis} and
\href{https://slu-soc5650.github.io}{GIS}) and GitHub organizations
(\href{https://github.com/slu-soc5050}{Quantitative Analysis} and
\href{https://github.com/slu-soc5650}{GIS}). Course materials are
available throughout the semester and after the course is done. This
creates two challenges. First, for all students, attention must be paid
to when updates are pushed to GitHub and the course website. This is
particularly true for content updated \emph{after} a lecture. Second,
for students who like to work ahead, care must be taken to ensure that
you are working off of materials for the current semester and not the
last semester the course was taught. There are two ways in which I help
communicate the status of course content - badges and Slack.

\hypertarget{badges}{\subsection{Badges}\label{badges}}

I use badges on both the GitHub \texttt{README.md} files in individual
lecture repositories and on individual lecture webpages to signal which
semester the content is current for and what stage of development the
content is in. These badges are used not just because they are effective
but as part of a more general socialization into data science software
development, where badges are used to signal development status on
\texttt{R} package GitHub repositories. For example, the
\href{https://github.com/tidyverse/ggplot2}{\texttt{ggplot2}}
\texttt{README.md} file looks like this:

\begin{center}\includegraphics[width=0.95\linewidth]{images/ggplot2Readme} \end{center}

There are four badges in total, all of which sit under the
\texttt{ggplot2} package name. We can see from the first two badges that
\href{https://en.wikipedia.org/wiki/Continuous_integration}{continuous
integration services} are used, and that \texttt{ggplot2} is only
passing its tests on one of them. The third badge indicates that the
built-in tests for \texttt{ggplot2} test 74\% of the package's code. We
can also see from the fourth badge that the current version of the
software on CRAN is version \texttt{2.2.1} (as of December, 2017).
Details like these are not critical when you are first learning to use
\texttt{R}, but they grow more important as your data science skills
progress.

We use the following badges for our course repositories and on the
course websites:

\begin{center}\includegraphics[width=0.95\linewidth]{images/readmeBadges} \end{center}

Here is an example of how the badges look on a course repository. As of
January 2018, the \texttt{README.md} associated with the
\href{https://github.com/slu-soc5050/Core-Documents}{\texttt{Core-Documents}
repository} for \href{https://slu-soc5050.github.io}{Quantitative
Analysis} looked like this:

\begin{center}\includegraphics[width=0.95\linewidth]{images/readmeBadgesEx} \end{center}

The \texttt{README.md} badges, from left to right, represent the
following:

\begin{enumerate}
\def\labelenumi{\arabic{enumi}.}
\tightlist
\item
  \textbf{semester}: the contents are current for the Fall 2017 semester
\item
  \textbf{release}: the contents have been updated since they were first
  released to students
\item
  \textbf{version}: the version number of the repository (see
  \protect\hyperlink{versioning}{Versioning} below) is \texttt{v17.4.2}
\item
  \textbf{last commit}: the last time the repository was edited was the
  day the screenshot was taken
\item
  \textbf{repo size}: the repository size is 2.46 megabytes (MB, see
  \href{https://www.computerhope.com/issues/chspace.htm}{this article}
  for details on what computer disk drive size measurements mean)
\end{enumerate}

Here is an example of how the badges look on a course website. As of
January 2018, the
\href{https://slu-soc5650.github.io/course-preview}{Course Preview page}
for \href{https://slu-soc5650.github.io/}{GIS} looked like this:

\begin{center}\includegraphics[width=0.95\linewidth]{images/webpageBadgesEx} \end{center}

From these three badges, we can see that the webpage is current for the
Spring 2018 semester and that it is the full release - no additional
updates to the site are planned. Finally, we can see the date on which
the page was last updated - December 29, 2017.

\hypertarget{versioning}{\subsection{Versioning}\label{versioning}}

The versioning system used on course repositories is meant to emulate
the release system used for data science software. Software development
increasingly takes place on a website called
\protect\hyperlink{github.com}{GitHub.com}. GitHub includes tools for
packaging a repository at particular points in time. The release system
allows developers to identify how an \texttt{R} package, for instance,
has changed over time. This is important for reproducibility. For
instance, you can see this example of the
\href{https://github.com/tidyverse/ggplot2/releases/tag/v2.2.0}{release
history for \texttt{ggplot2}}:

\begin{center}\includegraphics[width=0.95\linewidth]{images/release} \end{center}

The package's developers use the release system to document what has
changed. We will emulate this with the \texttt{Core-Documents}, lecture,
and \texttt{finalProject} repositories. For example, here is the release
documentation for
\href{https://github.com/slu-soc5650/Core-Documents}{SOC 4650/5650
\texttt{Core-Documents} repository}:

\begin{center}\includegraphics[width=0.95\linewidth]{images/releaseEx} \end{center}

If you want to see what has changed over the course of the semester in a
course's repositories, you can use the release notes to compare
different versions. These notes are also stored in the \texttt{NEWS.md}
file for each repository. The use of both releases and a
\texttt{NEWS.md} file is a common way to document changes on GitHub. For
example, you can see look at the
\href{https://github.com/tidyverse/ggplot2/blob/master/NEWS.md}{\texttt{NEWS.md}
file for \texttt{ggplot2}}, which will mirror the
\href{https://github.com/tidyverse/ggplot2/releases}{release notes} for
the package.

In software development,
\href{https://en.wikipedia.org/wiki/Software_versioning}{version
numbers} are used along with releases to make it easy for end users to
keep track of how releases have progressed. In the picture above of the
\texttt{ggplot2} package's \texttt{README.md} (see
\protect\hyperlink{badges}{Badges}), one of the badges indicated the
version of the software that was available via CRAN - \texttt{2.2.1}.
The initial \texttt{2} is what is known as the major release number.
Major releases typically represent large changes to the software. The
second number, also a \texttt{2} in this case, represents the minor
release number. Minor releases introduce fewer changes and may be aimed
more at fixing issues. Finally, the \texttt{1} represents the patch
release number. Patch (or maintenance) releases are aimed exclusively at
fixing bugs and issues.

For the course, version numbers will also have three parts. From left to
right, the first pair of digits represents the year of the current
course offering, the second pair represents whether it the development
status is (\texttt{1}) draft, (\texttt{2}) lecture, (\texttt{3}) full,
and (\texttt{4}) updated, and the final number represents maintenance
changes that do not rise to a change in the development status. For
example, \texttt{v18.1.1} would represent the initial maintenance
release for the 2018 version of a course that is in the draft
development stage.

If you see a version number like \texttt{v18.1.1.9000} in
\texttt{NEWS.md}, the notes will be tracking changes that have not been
incorporated into an official release yet. The use of the \texttt{9000}
designation follows \href{http://r-pkgs.had.co.nz/release.html}{common
practice in the \texttt{R} community}.

\subsection{Slack}\label{slack}

The \texttt{\#\_news} channel in each course's Slack organization will
be automatically updated with a list of commit messages for each lecture
repository. The updates will look like this:

\begin{center}\includegraphics[width=0.95\linewidth]{images/slackNews} \end{center}

You will be able to scan through commit messages for updates that might
be relevant for you. Commit messages are a core part of using Git, and
are discussed in the \protect\hyperlink{basic-git}{Basic Git} chapter.
From these messages, we can see that changes were made to the
\texttt{LICENSE} (one of the meta documents) in the
\href{https://github.com/slu-soc5650/Core-Documents}{\texttt{Core-Documents}
repository} for \href{https://slu-soc5650.github.io/}{GIS}. We can also
see that a change was made to the Syllabus's content for the course.

I recommend scanning through all new messages in \texttt{\#\_news} each
time you check in with the course on Slack. If you see changes, sync
your repository (if you are keeping local copies) or download the
updated document.

\hypertarget{good-enough-research-practices}{\chapter{\texorpdfstring{``Good
Enough'' Research
Practices}{Good Enough Research Practices}}\label{good-enough-research-practices}}

This section introduces some of the core concepts that support
sociospatial data science works. The title of the chapter takes
inspiration from a recent article titled
\href{http://journals.plos.org/ploscompbiol/article?id=10.1371/journal.pcbi.1005510}{\emph{Good
enough practices in scientific computing}} (Wilson et al. 2017). The
authors note in their introduction that scientific computing advice can
sometimes be both overwhelming and focused on tools that are
inaccessible to many analysts. Their goal, and the goal of this text, is
to de-mystify the simplest tools that enable researchers to streamline
their workflows:

\begin{quote}
Our intended audience is researchers who are working alone or with a
handful of collaborators on projects lasting a few days to a few months,
and who are ready to move beyond emailing themselves a spreadsheet named
\texttt{results-updated-3-revised.xlsx} at the end of the
workday\ldots{}Many of our recommendations are for the benefit of the
collaborator every researcher cares about most: their future self.
\end{quote}

I would argue that the skills they describe are useful beyond just a few
months. Indeed, most of the skills here can dramatically improve
students' dissertation experiences:

\begin{quote}
Most importantly, these practices make researchers more productive
individually by enabling them to get more done in less time and with
less pain. They also accelerate research as a whole by making
computational work (which increasingly means all work) more
reproducible. But progress will not happen by itself. Universities and
funding agencies need to support training for researchers in the use of
these tools. Such investment will improve confidence in the results of
computational work and allow us to make more rapid progress on important
research questions.
\end{quote}

While much of what we will talk about in this text is aimed at
supporting your work, there are benefits that extend beyond your
dissertation or your research projects. These benefits, which include
developing sustainable workflows and structuring the way you interact
with your own computer, can make everyday computing practices like
checking email or organizing files an easier, more structured process.

\section{Reproducibility}\label{reproducibility}

One of the mantras of this text is an emphasis on reproducibility. The
unifying feature of all of the ``good enough'' research practices
discussed below is that they contribute to a more reproducible research
product.

Reproducibility is very much in vogue right now for number of reasons.
\href{http://science.sciencemag.org/content/349/6251/aac4716}{Assessments
of studies in psychology}\footnote{Open Science Collaboration, 2015.
  Estimating the reproducibility of psychological science.
  \emph{Science}, 349(6251), p.aac4716.}, for example, have found weaker
on average effect sizes and far fewer statistically significant results
than the initial studies reported. There have also been high profile
instances of falsified research, including
\href{http://nymag.com/scienceofus/2015/05/how-a-grad-student-uncovered-a-huge-fraud.html}{research
by a graduate student at UCLA}. This particular instance of fraud was
identified by graduate students intent on replicating the original
study.

At the same time, there is a recognition that the skills necessary for
producing reproducible research are not being fostered in academic
disciplines and graduate programs. Thus one of the goals of this course,
and this \textbf{User's Guide} in particular, is to help develop a
working knowledge of many of these skills.

One challenge, however, is that reproducibility does not have a
consistent definition. Some researchers use the term to narrowly refer
to code that can execute without alteration on a person's computer.
Others use it to refer to research designs that can be replicated by
other researchers. Still others discuss reproducibility as the ability
to obtain a similar set of results or draw similar inferences from
identical research designs.

When we talk about reproducibility in this class. We'll be primarily
concerned with \textbf{methods reproducibility}:

\begin{quote}
the ability to implement, as exactly as possible, the experimental and
computational procedures, with the same data and tools, to obtain the
same results.\footnote{Goodman, S.N., Fanelli, D. and Ioannidis, J.P.,
  2016. What does research reproducibility mean?. \emph{Science
  translational medicine}, 8(341), pp.341ps12-341ps12.}
\end{quote}

Methods reproducibility in statistics means that other analysts have
full access to both the original data and the steps used to render those
original data into a final research product, such as a set of regression
models This is increasingly seen not just a matter of good research
methodology, but as a matter of research ethics as well. Being able to
be transparent with research decreases the potential for cases like the
\href{http://nymag.com/scienceofus/2015/05/how-a-grad-student-uncovered-a-huge-fraud.html}{fraudulent
dissertation research conducted by a UCLA graduate student named Michael
LaCour}. It was the efforts of
\href{https://fivethirtyeight.com/features/how-two-grad-students-uncovered-michael-lacour-fraud-and-a-way-to-change-opinions-on-transgender-rights/}{two
Stanford graduate students who wanted to reproduce LaCour's findings}
that ultimately led to the identification of problematic work.

For statistics, methods reproducibility is derived from a number of
sources. The first source is the use of \textbf{computer code} for
working with data. Rather than making manual changes to tabular data in
a spreadsheet application like Microsoft Excel, computer code provides
detailed records of each individual alterations. Code can be used
execute tasks repeatedly, meaning that errors can be easily fixed if
they are discovered an hour, a day, a week, or a month later. During
this semester, we'll use \texttt{R}'s programming language to execute
reproducible data cleaning processes.

The second source of reproducibility in statistics is therefore derived
from the \textbf{documentation} that we create to accompany our research
products. These documents outline where our data originated, what
specific variables mean (a codebook), what steps were taken to create
specific maps (a research log), and how our data files are organized (a
metadictionary).

Our code can also be used as documentation if it is written using
\href{https://en.wikipedia.org/wiki/Literate_programming}{literate
programming} techniques. In \texttt{R}, these techniques produce well
annotated output that ``weaves'' together code, output, and narrative
text that describes the function of the code and the results of the
output.

The third and final primary source of reproducibility in statistics is
derived from our \textbf{organizational approach} to our work.
Statistics projects can require many megabytes of data spread across
dozens of data files, scripts, and output files. A disorganized file
system can make replicating your work difficult if not impossible. Much
of the research practices discussed in the remainder of this section are
aimed at supporting one or more of these three major sources of
reproducibility.

\section{Thinking in Workflows}\label{thinking-in-workflows}

One way to increase the reproducibility of a project is to approach each
and every task with purposeful organization and thoughtfulness.
\textbf{Workflows} are the processes that we use to approach a given
task. Think of checking your email. You (hopefully!) follow a series of
steps when you check your email that help you organize your inbox. In
his excellent primer \emph{The workflow of data analysis using Stata}
(2009), Scott Long describes a structured strategy for approaching
statistical research. In Long's model, a data analysis project consists
of four steps: (a) data cleaning, (b) analysis, (c) presenting results,
and (d) protecting files. This is a useful model to build upon, and one
that we will discuss over the course of the semester.

Even more useful, not just for statistical work but for any process, are
the tasks Long lays out for each step in the data analysis workflow:

\begin{enumerate}
\def\labelenumi{\arabic{enumi}.}
\tightlist
\item
  Planning
\item
  Organization
\item
  Documentation
\item
  Execution
\end{enumerate}

A good example of the utility of extending this logic to other workflows
is with the problem sets. The ``typical'' approach students take with
homework assignments is to sit down, open up their software, and start
with question 1. Using Long's four task approach, a workflow-based
strategy to the assignment would involve beginning by reading the
assignment through in its entirety to develop a \textbf{plan} for
approaching it - think about what techniques and skills are needed for
each step. With a plan in place, you can proceed to \textbf{organizing}
yourself for the assignment - identifying and obtaining files that you
will need, creating dedicated directories for saving assignment data,
and getting any necessary software documentation. After pulling together
all of these materials, you are ready to move on to
\textbf{documentation} - setting up your assignment code and output
files, and (later in the course) your research log and meta-dictionary.
Once you are set-up, you would then begin to address individual
assignment questions as part of the \textbf{execution} task.

The goal here is to approach everything you do for research or work with
an element of mindfulness and structure about your process. This mental
model for approaching research supports the creation of
\textbf{reproducible} research products because we approach our work in
a routinized, predictable, organized, and efficient manner. Thinking in
terms of workflows also encourages a greater awareness of the complexity
of tasks, which also helps you plan more accurately for how long a
particular task or project will take.

In reality, there will be multiple workflows that you find yourself
navigating. You will want a structured process not just for approaching
a large research project like the final project, but also a process for
maintaining notes related to a specific assignment, a process for
documenting code, a process for approaching assignments, and even a
process for backing your data up. As you go through the text, think
about how to best integrate these ideas into your work habits.

\section{Data}\label{data-1}

One of the themes in
\href{http://journals.plos.org/ploscompbiol/article?id=10.1371/journal.pcbi.1005510}{\emph{Good
enough practices in scientific computing}} (Wilson et al. 2017) is an
emphasis on data management. One of their core messages is to ``save the
raw data''. Particularly in GISc work, the raw data can be expansive -
dozens of shapefiles, tabular files, and associated metadata. These
files often come from disparate sources - city open data sites, the U.S.
Census Bureau, state data repositories, and other federal agencies.
Moreover, GIS data are often updated over time to reflect on-the-ground
changes. Saving the raw data in sociospatial data science work therefore
means not only creating a well-organized directory containing \emph{all}
of your original data. It also means logging the source of each file,
when it was downloaded, and (if applicable) a permanent web link to your
data source. For that reason, we'll give you not just the course data
but a read me file and a metadictionary that lists all of the files
we've disseminated to you.

A second message in the paper is to ``create the data you wish to see in
the world''. The authors encourage readers to ``create the data set you
wish you had received.'' First and foremost, this means using open and
not proprietary data formats. For spatial data,
\href{https://en.wikipedia.org/wiki/Shapefile}{ESRI shapefiles} are
technically proprietary, though their standard is open. This means that
other software applications, like \texttt{R} and QGIS can read and in
some cases write shapefiles. For sharing spatial data, a better option
is the \href{https://en.wikipedia.org/wiki/GeoJSON}{GeoJSON}, which is a
plain text file format. Tabular data are best stored as \texttt{CSV}
files, which is also a plain text file format that can be opened by a
wide variety of applications. In contrast, common file formats like
Microsoft Excel's \texttt{XLS} and \texttt{XLSX} are proprietary file
packages that cannot be read as plain text and are therefore less
desirable for storing data.

\section{Plain Text}\label{plain-text}

Along with creating the data we wish to see,
\href{http://journals.plos.org/ploscompbiol/article?id=10.1371/journal.pcbi.1005510}{\emph{Good
enough practices in scientific computing}} (Wilson et al. 2017)
repeatedly emphasizes the importance of using plain text files for
writing as well as for data. Using plain text file formats, like
\texttt{.txt} and \texttt{.md} files, frees us from reliance on
proprietary applications that we cannot be sure will exist in ten or
twenty years (and are thus threats to reproducible research). They can
also be opened on virtually any computer across a variety of operating
systems. The authors of the article reference
\protect\hyperlink{markdown}{Markdown} files, which a really just
plain-text files containing special characters that can be rendered by
websites and other applications. \protect\hyperlink{markdown}{Markdown},
which is discussed later in this text, provides us with the best of both
worlds. We can produce outputs with rich text like styling but that is
saved in a plain text file container. Writing in a markup language can
seem daunting at first, but within a few weeks I have found that most
people can start to feel comfortable inserting markup syntax without
significant cognitive burden.

\section{Version Control}\label{version-control}

One of the key emphases of both
\href{http://journals.plos.org/ploscompbiol/article?id=10.1371/journal.pcbi.1005510}{\emph{Good
enough practices in scientific computing}} (Wilson et al. 2017) and
\href{https://peerj.com/preprints/3210/}{``opinionated analysis
development''} is that data science work should be tracked using version
control software. This text introduces \href{https://git-scm.com}{Git}
in the \protect\hyperlink{basic-git}{Basic Git} chapter, though there
are other options like \href{http://subversion.apache.org}{Subversion}
and \href{https://www.mercurial-scm.org}{Mercurial}. Git is introduced
because it has been widely adopted by the \texttt{R} community and
because of the robust web tools associated with
\href{http://github.com}{GitHub.com}. Using version control gives us a
timeline of our work along with the ability to revert back to previous
versions of our files. This creates a ``chain of evidence'' for our
research process and protects us from irrevocably altering files.

As the authors of
\href{http://journals.plos.org/ploscompbiol/article?id=10.1371/journal.pcbi.1005510}{\emph{Good
enough practices in scientific computing}} (Wilson et al. 2017) note,
learning version control software can be tricky. There are two chapters
later in this text dedicated to \href{https://git-scm.com}{Git} covering
both \protect\hyperlink{basic-git}{Basic Git} and
\protect\hyperlink{advanced-git}{Advanced Git} techniques. Those
chapters also provide links to other resources and tips for using those
tools successfully.

\hypertarget{protecting-your-work}{\chapter{Protecting Your
Work}\label{protecting-your-work}}

One of the biggest challenges to with doing computational work is that
it requires a high degree of organization. Our approaches to file
management on computers are often haphazard, with \texttt{Documents} and
\texttt{Downloads} folders filled with disorganized files or a
\texttt{Desktop} covered in dozens of files. Perhaps this has worked in
the past, but that approach (or lack thereof) \textbf{will} fail
students in \href{https://slu-soc5650.github.io}{Introduction to
Geographic Information Science (SOC 4650/5650)} and
\href{https://slu-soc5050.github.io}{Quantitative Analysis: Applied
Inferential Statistics (SOC 4930/5050)}. Moreover, if left un-checked,
it will fail students down the road when a hard drive failure or natural
disaster renders their data irrevocably inaccessible. This chapter
covers what some of those threats are and ways to manage those risks
when conducting computational research.

\section{Threats To Our Data}\label{threats-to-our-data}

Each semester that I teach
\href{https://slu-soc5650.github.io}{Introduction to GIS} and
\href{https://slu-soc5050.github.io}{Quantitative Analysis}, several
things happen. The first thing that happens is that students regularly
lose files. The effects of losing files can range from being a minor
frustration to a major headache depending on the file in question.
Losing files often results in downloading multiple copies of the same
data and recreating work. Both of these are wastes of your time.
Moreover, files are rarely gone. They are typically just misplaced. This
is bad for reproducibility, particularly when you happen across multiple
versions of the same file and have to sort out which version is the
version you last worked on.

The second thing that happens is that students who use thumb drives for
data storage lose them. Depending on the timing of this loss, this can
again range from being a minor frustration (very early in the semester)
to being downright anxiety attack producing (last few weeks of the
semester). Recreating an entire semester's worth of work on the final
project is both a tremendous waste of your time and a particularly
unpleasant experience.

Fortunately, I have never had a student's computer hard drive die during
the course of the semester. However, I assume that if I teach this
course long enough a hard drive failure will indeed occur. The backup
provider \href{https://www.backblaze.com/}{Backblaze} has
\href{https://www.backblaze.com/blog/how-long-do-disk-drives-last/}{analyzed}
their own hard drives and found that about 5\% of drives fail within the
first year. After four years, a quarter (25\%) of drives in their data
center fail. Similarly, it is only a matter of time before a student's
computer is stolen along with all of their hard work. A less likely
though still very plausible scenario involves the destruction of a
student's belongings (computer and thumb drive included) in a fire, car
accident, or natural disaster.

Despite the likelihood that you will at some-point lose a thumb drive
(if not during this semester than sometime down the road) and the near
certainty that your computer's hard drive will eventually fail if a
rogue wave does not get it first, few students and faculty take these
risks seriously. While you cannot prevent many of these things from
happening, I want to suggest to you that you can take some simple steps
to sure that \emph{when} (not if) they happen, you are well prepared to
get back to work with minimal disruption.

\hypertarget{creating-a-sustainable-file-system}{\section{Creating a
Sustainable File System}\label{creating-a-sustainable-file-system}}

The first thing that students can do to stave off problems with lost
files is to actively and mindfully manage their files. In his excellent
document \href{http://plain-text.co}{\emph{The Plain Person's Guide to
Plain Text Social Science}}, Kieran Healy describes two important
revolutions in computing that are currently taking place. One of them is
the advent of mobile touch-screen devices, which he notes

\begin{quote}
hide from the user both the workings of the operating system and
(especially) the structure of the file system where items are stored and
moved around.
\end{quote}

For most users, I would argue that this extends to their laptop or
desktop computers as well. I would venture to guess that the majority of
my students are used to keeping large numbers of files on their desktops
or in an (distressingly) disorganized \texttt{Documents} folder. For
research, particularly quantitative research, such an approach to file
management is unsustainable. It is difficult to produce \emph{any}
research, let alone work that is reproducible, without an active and
mindful approach to file management.

\subsection{\texorpdfstring{Create a \emph{Single} Course
Directory}{Create a Single Course Directory}}\label{create-a-single-course-directory}

The most successful approach to organizing files is to identify
\emph{one and only one} area that you will store course files in. Having
files scattered around you hard drive between you \texttt{Desktop}
directory, \texttt{Downloads}, \texttt{Documents}, and a half dozen
other places is a recipe for lost files. It can also add complexity to
the task of backing these files up. I recommend naming this directory
simply based on the course you are enrolled in:

\begin{itemize}
\tightlist
\item
  \texttt{SOC4650}
\item
  \texttt{SOC4930}
\item
  \texttt{SOC5050}
\item
  \texttt{SOC5650}
\end{itemize}

These names are short, have no punctuation or spaces (which can create
conflicts with software), and explicitly connects the directory to this
course as opposed to other courses you may take that are also statistics
or GIS courses (a good reason to avoid naming the directory
\texttt{Stats} or \texttt{GIS}!).

This single course directory should reside in \emph{one and only one}
place. Once you have these folders set-up, I want you to an agreement
with yourself: files for the course will \emph{only} be saved within
this structure. Do not temporarily save files to the \texttt{Desktop},
for example, intending to move them later. They will be forgotten. Like
New Years resolutions, it is easy to say that you will use a file system
but difficult to maintain that promise when stress sets in or you are
rushed. Do \emph{everything} you can to maintain your file system.

\subsection{Storing the Course
Directory}\label{storing-the-course-directory}

Storing this directory inside a sync'd directory (like Dropbox or Google
Drive) may cause conflicts with your Git repositories. Instead, students
for both of my courses should utilize a large sized thumb drive or an
external hard drive for data storage (see the ``Course Onboarding''
section of the respective course's website for additional details).
Having data stored on an external device raises the risk of physical
loss, but also makes it easier to move work between different computers.
This is particularly challenging for GI Science work, where spatial data
sources can be may megabytes in size.

macOS users should make sure that the external drive is formatted using
the ExFat file system specification so that it is readable both by their
operating system and the Windows operating system in the computer lab.
If you buy a new drive, you will likely have to re-format it. Directions
for doing so are
\href{https://support.apple.com/kb/PH22241?locale=en_US}{available from
Apple}.

\subsection{Approach Organizing
Systematically}\label{approach-organizing-systematically}

Within your single course directory, I recommend following a mindful,
purposeful approach to organization. This approach begins with having a
number of dedicated subfolders within your course directory:

\begin{verbatim}
/SOC5650
  /Core-Documents
  /DataLibrary
  /DoeAssignments
  /Lectures
  /Notes
  /Readings
\end{verbatim}

Note again how these directories are named - there are no spaces,
special characters, and the names are deliberately short but specific.
For a directory with two words (e.g. \texttt{DataLibrary}), I use what
is known as camelCase to name the file where the second (any any
subsequent) words have their first character capitalized. You could also
use dash-case (e.g. \texttt{Core-Documents}) or snake\_case (e.g.
\texttt{Core\_Documents}) as a naming strategy. Regardless of which of
these approaches you take, try to use it consistently.

For both of the courses that I teach, a basic file system will be made
available for download onto your external device. See the respective
course websites for more information about course data releases. Only
the data release for \href{https://slu-soc5650.github.io}{Introduction
to Geographic Information Science (SOC 4650/5650)} will contain a
\texttt{DataLibrary} directory.

\subsection{\texorpdfstring{The \texttt{Core-Documents}
Directory}{The Core-Documents Directory}}\label{the-core-documents-directory}

The \texttt{Core-Documents} directory is used for storing the course
syllabus, reading list, and a sample schedule for 3600 Morrissey Hall
for the semester. You can view it online for both
\href{https://github.com/slu-soc5050/Core-Documents}{Introduction to
GIS} and
\href{https://github.com/slu-soc5650/Core-Documents}{Quanitative
Analysis}. Once we cover using Git and GitHub in class, you should
\textbf{clone} the appropriate \texttt{Core-Documents} repository into
your file system. If there are updates, you will want to make sure you
\textbf{pull} them down onto your local copy of the repository. You can
read ahead in the \protect\hyperlink{basic-git}{Basic Git} chapter for
more information on how this works.

You will not be able to \textbf{push} changes that you make in this
directory to GitHub, and making other changes could cause conflicts. I
suggest not making changes inside this repository beyond opening files
for reference purposes.

\subsection{\texorpdfstring{The \texttt{DataLibrary}
Directory}{The DataLibrary Directory}}\label{the-datalibrary-directory}

This directory is only applicable to students in
\href{https://slu-soc5650.github.io}{Introduction to GIS}, whose data
release will contain it. It will have copies of most data not
disseminated to you as \texttt{R} packages. The data in this directory
should be used as needed but not altered (one of the of the
\protect\hyperlink{good-enough-research-practices}{``Good Enough''
Research Practices} from the next chapter).

\subsection{\texorpdfstring{The \texttt{DoeAssignments}
Directory}{The DoeAssignments Directory}}\label{the-doeassignments-directory}

Like the \texttt{Core-Documents} repository, this will not be included
in the course data release. Once we cover using Git and GitHub in class,
you should \textbf{clone} the appropriate \texttt{Core-Documents}
repository into your file system. It will also have a different name -
your last name instead of `Doe'. Once you add it, it will contain a
number of subdirectories:

\begin{verbatim}
  /SOC5650
    /DoeAssignments
      /FinalProject

      /Labs
        /Lab-01
        ...
        /Lab-15

      /LecturePreps
        /LP-01
        ...
        /LP-15
        
      /ProblemSets
        /PS-01
        ...
        /PS-08
\end{verbatim}

The \texttt{FinalProject} directory will not have any subfolders in it.
You will be asked to populate it with the appropriate subdirectories
(see \protect\hyperlink{organizing-projects}{Organizing Projects}
below). These will be detailed in the final project instructions. The
\texttt{Labs}, \texttt{LecturePreps}, and \texttt{ProblemSets}
subdirectories have folders dedicated to the individual assignments
you'll have to submit over the course of the semester. Like the
\texttt{FinalProject} directory, you will need to populate them with the
appropriate deliverables. These will be detailed in each assignment's
instructions.

\subsection{\texorpdfstring{The \texttt{Lectures}
Directory}{The Lectures Directory}}\label{the-lectures-directory}

This directory should contain subfolders for each of the sixteen weeks
of the course.

\begin{verbatim}
  /SOC5650
    /Lectures
      /Lecture-01
      ...
      /Lecture-16
\end{verbatim}

You will need to add these subfolders each week by \textbf{cloning} them
from GitHub.com. You will not be able to push changes that you make in
these directories to GitHub, and making other changes could cause
conflicts. I suggest not making changes inside this repository beyond
opening files for reference purposes. If there is something you need to
edit, copy it to the appropriate subdirectory of \texttt{DoeAssignments}
and make your changes there.

\subsection{\texorpdfstring{The \texttt{Notes}
Directory}{The Notes Directory}}\label{the-notes-directory}

Use this as a home for course notes if you decide to take notes
digitally and do not already use notebook software of some kind that
organizes notes for you.

\subsection{\texorpdfstring{The \texttt{Readings}
Directory}{The Readings Directory}}\label{the-readings-directory}

Use this as a home for \texttt{.pdf} copies of course readings. I
suggest creating subdirectories \emph{only} for weeks that have readings
assigned from outside of the main texts, such as Lecture 01:

\begin{verbatim}
  /SOC5650
    /Readings
      /Lecture-01
\end{verbatim}

\hypertarget{organizing-projects}{\section{Organizing
Projects}\label{organizing-projects}}

Following the excellent article
\href{http://journals.plos.org/ploscompbiol/article?id=10.1371/journal.pcbi.1005510}{\emph{Good
enough practices in scientific computing}} (Wilson et al. 2017), I
suggest data science projects should be organized in a specific,
standardized way. This approach serves much the same purpose as the
previous section on
\protect\hyperlink{creating-a-sustainable-file-system}{Creating a
Sustainable File System} - work that is well organized is better insured
against loss.

\subsection{A Sample Project}\label{a-sample-project}

Much as I suggested above that course files reside in one and only one
place, projects should be organized similarly (with one important caveat
below). What follows is a sample project and then descriptions of each
element. More details about each folder (excepting \texttt{maps}) can be
found in the article. The project below contains all of key elements of
a small geospatial research project:

\begin{verbatim}
  /projectName
    /data
      rawData.csv
      rawTracts.shp
    /doc
      joinedTracts.md
      notebook.Rmd
      notebook.nb.html
      researchLog.md
    /maps
      map.mxd
    /results
      joinedTracts.shp
      map.png
    /src
      script.R
    LICENSE.md
    projectName.Rproj
    README.md
\end{verbatim}

\subsection{Top-Level Files}\label{top-level-files}

At least two files should be present in each project directory - a
\texttt{README.md} and a \texttt{LICENSE.md}. As I noted in the previous
chapter, both of these files should be plain-text files. Typically, they
are formatted using \protect\hyperlink{markdown}{Markdown} syntax The
\texttt{README} should describe your project, detail any key
dependencies or outside data sources that might be required, and provide
other important details like how to cite your project and what other
online resources might be available.

The \texttt{LICENSE} is a key element of open source research. This
spells out how others may use (and not use) your work. The excellent
guide \href{https://opensource.guide/}{The Legal Side of Open Source}
notes:

\begin{quote}
Open source is an unusual circumstance\ldots{}because the author expects
that others will use, modify, and share the work. But because the legal
default is still exclusive copyright, you need a license that explicitly
states these permissions.
\end{quote}

There are lots of different options for open source licenses, and
\href{https://choosealicense.com}{GitHub's choose a license site} does a
great job of explaining some of the
\href{https://choosealicense.com/appendix/}{many options}. In the
\texttt{R} community, many packages are made available using the
\href{https://choosealicense.com/licenses/mit/}{MIT} or
\href{https://choosealicense.com/licenses/gpl-3.0/}{GNU GPLv3} licenses.
For written content, presentations, and other non-code works, the
Creative Commons
\href{https://choosealicense.com/licenses/cc-by-4.0/}{Attribution} and
\href{https://choosealicense.com/licenses/cc-by-sa-4.0/}{Attribution-ShareAlike}
licenses are both common options. For data, the
\href{https://opendatacommons.org}{Open Data Commons} licenses are not
discussed on GitHub's site but are options for data-specific licenses.
Finally, large projects sometimes require
\href{https://choosealicense.com/non-software/}{multiple licenses}. If
you use a data-specific, code-specific, and/or content-specific mix of
licenses, be sure to describe in the \texttt{README} which license
applies to which element of of the project. Licensing your projects is
another form of protecting your work. If these projects are out in the
open, licensing ensures that your work will be used under terms that you
are comfortable with.

If the project uses \texttt{R}, an \texttt{R} project file
(\texttt{.Rproj}) should also be saved in the top-level of the project.
This will facilitate the top-level folder being set automatically as the
\href{https://en.wikipedia.org/wiki/Working_directory}{working
directory}. The working directory is the folder that \texttt{R} will
open data from and save data to by default.

\subsection{\texorpdfstring{The \texttt{data}
Directory}{The data Directory}}\label{the-data-directory}

All data sources, with a few exceptions, should be stored here. For
instance, in the example above, a tabular data source and a raw
shapefile are both used as part of the project. There are, however, a
number of exceptions to this. One exception is data that has been
packaged in an \texttt{R} package. For example, I have packaged a large
set of tables containing historical census data to make them easier to
work with. When these are used in projects, I do not save the tables in
the \texttt{data} folder. Rather, I make reference to them in the
\texttt{README} file and in other project documents.

A second exception is for large geospatial data libraries, like the data
release for my \href{https://slu-soc5650.github.io}{Introduction to
GIS}. Given the size of these files, it is sometimes impractical to
reproduce them multiple times across different projects. Clearly noting
that specific files are stored on local libraries available elsewhere in
the \texttt{README} file and in other project documents is also an
acceptable alternative here.

\subsection{\texorpdfstring{The \texttt{doc}
Directory}{The doc Directory}}\label{the-doc-directory}

The \texttt{doc} directory should be used for all text documents
associated with the project. These might include metadata associated
with different project data files, an interactive \texttt{R} notebook, a
research log file, and article manuscripts. If needed, subdirectories
within \texttt{doc} should be used to keep different files organized. In
the example above, \texttt{joinedTracts.md} is the metadata for the
similarly named shapefile in the \texttt{data} subdirectory. The
\texttt{notebook} files are the interactive \texttt{R} notebook and its
associated \texttt{html} output. Finally, the \texttt{researchLog.md} is
used for tracking higher level progress over the course of the project.

\subsection{\texorpdfstring{The \texttt{maps}
Directory}{The maps Directory}}\label{the-maps-directory}

\texttt{maps} is a deviation from
\href{http://journals.plos.org/ploscompbiol/article?id=10.1371/journal.pcbi.1005510}{\emph{Good
enough practices in scientific computing}} (Wilson et al. 2017), which
does not envision some of the complexity of working with geospatial
data. It should be used for storing the \texttt{.mxd} files from ArcGIS
projects or the equivalent QGIS files if that application is being used
instead. Illustrator files used for post-processing work should also be
stored here if used. Remember that these files should be saved using
relative paths to link them to data sources to limit the possibility of
conflicts down the road.

\subsection{\texorpdfstring{The \texttt{results}
Directory}{The results Directory}}\label{the-results-directory}

The \texttt{results} directory should contain any data outputs, plots,
and map images. These might include intermediate and final versions of
data sets as well as shapefiles and GeoJSON files created as part of the
analysis process. In the example above, a shapefile combining both of
the raw data sources named \texttt{joinedTracts.shp} is saved here along
with the exported map image from the map file in the \texttt{maps}
subdirectory. Depending on the complexity of the project, subdirectories
within \texttt{results} might be necessary.

\subsection{\texorpdfstring{The \texttt{src}
Directory}{The src Directory}}\label{the-src-directory}

For projects that rely on functions not included in packages, for
example, or that rely on other pre-made scripts, the \texttt{src}
subdirectory should be used for storing script files that are called by
notebooks in \texttt{doc}.

\subsection{Storing Your Project}\label{storing-your-project}

There are a number of places where work can be deposited. I teach all
students in my classes how to use \href{https://github.com}{GitHub.com}
because it integrates directly into version control software, which I
see as a critical component of
\protect\hyperlink{good-enough-research-practices}{``Good Enough''
Research Practices}. There are other options, however. For larger
projects that may not just be on GitHub (see
\protect\hyperlink{basic-git}{Basic Git}) but also utilize a
collaborative writing space like Google Docs, the
\href{https://osf.io}{Open Science Framework} is an excellent tool. It
allows for an even wider set of version control tools to be applied to
projects and can be used to organize work that is not easily stored on
GitHub, like large number of pdf articles, for which version control is
not critical.

Once a research project has begun dissemination, repositories like
\href{https://zenodo.org}{Zenodo} and
\href{https://figshare.com}{Figshare} are designed to make open source
data and project materials accessible and citeable. For papers
specifically, there are a number of discipline specific archives for
pre-prints of papers. Many journals will allow pre-prints to remain
freely available even after more formal publication. The original
pre-print archive, \href{https://arxiv.org}{arXiv}, is focused on the
STEM sciences and has inspired a number of spinoffs. Many of these are
supported by the \href{https://cos.io}{Center for Open Science}, the
same organization that operates the \href{https://osf.io}{Open Science
Framework} tool described above. For social scientists,
\href{https://socopen.org/welcome/}{SocArXiv} is a growing pre-print
repository that is part of the
\href{https://osf.io/preprints/socarxiv}{Center for Open Science's
pre-print network}.

\subsection{Organizing Coursework}\label{organizing-coursework}

For \href{https://slu-soc5650.github.io}{Introduction to Geographic
Information Science (SOC 4650/5650)} and
\href{https://slu-soc5050.github.io}{Quantitative Analysis: Applied
Inferential Statistics (SOC 4930/5050)}, problem sets and the final
project should both be organized following the general template above.

\section{Backing Up Your Data}\label{backing-up-your-data}

All of the organization in the world cannot prevent a computer hard
drive from failing or a natural disaster from destroying your hardware.
Similarly, even the best organized of us lose things sometimes or
accidentally delete files. Backing up files is therefore a critical
piece of not just doing computational work but, in this day and age, it
is a requisite skill for owning computer hardware. Every device you own
including your phone can and should be backed up. There are a number of
different ways to think about backing up your data. The most successful
backup strategies will incorporate all of these three elements.

\subsection{Bootable Backups}\label{bootable-backups}

``Bootable'' backups are mirrored images of your \emph{entire} hard
drive, down to temporary files, icons, and system files. With a bootable
backup, you can restore your entire computer in the event of a hard
drive failure or a corruption of the operating system files. They are
named as such because you can plug in the external drive that you are
using for this backup and literally boot your computer up from that
drive (typically a \emph{very} slow process).

These backups are often made less frequently because they can be
resource intensive and it is best not to use your operating system while
creating a clone. They are typically made to an external hard drive,
which is subject to similar failure rates as the hard drives inside your
computer. So bootable drives need to be replaced every few years to
maintain their reliability.

Both major operating systems come with applications for creating clones
of your main hard drive that are bootable, and there are a number of
third party applications that provide this service as well.

\subsection{Incremental Backups}\label{incremental-backups}

Incremental backups are designed to keep multiple copies of a single
file (how often depends on the type of software you use and the settings
you select). These can be used to restore an older copy of a file if
work is lost or a newer file is corrupted.

Apple's TimeMachine is a great example of an incremental backup - when
kept on, it creates hourly backups of files that have been changed,
daily backups for the previous month, and weekly backups for previous
months. Once the disk is full, the oldest backups are deleted. Dropbox
also provides a similar service, retaining all previous versions of
files (and deleted files) for thirty days.

Incremental backups are typically good options for recovering files that
have been recently changed (again, depending on the software you use and
the settings you select). Since they run frequently (every time a file
is changed or every hour, for example), recent changes tend to get
captured. They can be limited in terms of their long-term storage - it
may not be possible to recover older versions of a file past a few
weeks.

They are also not always good solutions for recreating your entire
computer since they do not save all necessary program and operating
system files, and may be cumbersome to work with if you need to recover
a large quantity of files. Like bootable backups, these are typically
stored on external hard drives that need to be replaced on a regular
basis.

In addition to the aforementioned Apple TimeMachine, the Windows OS also
comes with a built-in service for creating incremental backups. Dropbox
is a good option if you have a small number of files, but you may find
the need to upgrade to a paid account if you have a large amount of
data.

\subsection{Cloud Backups}\label{cloud-backups}

Cloud backup services like \href{https://www.backblaze.com}{Backblaze}
or \href{https://www.code42.com/crashplan/}{Crashplan} offer
comprehensive backup solutions for customers. These plans typically
require a monthly subscription fee to maintain access to your backups.
While bootable backups protect against hard drive failure and
incremental backups protect against data corruption, cloud backups
protect against catastrophic events like robberies, fires, and other
natural disasters. A fire or a tornado that affect your house may
destroy your laptop and any external hard drives you use for backup, but
your cloud backup will be unaffected.

\subsection{A Workflow for Backups}\label{a-workflow-for-backups}

Just as we need a workflow for approaching file management, it is also
important to establish a routine for backups. With backups, the most
successful workflows are those that require next to no effort on your
part. If you primarily use a desktop, this can be as simple as leaving
two external hard drives plugged into your computer since most backup
software can be set to run automatically. If you have tasks that require
you to manually do something (plug an external hard drive into your
computer, for instance), create a reminder for yourself on a paper
calendar or a digital calendar or to-do list application.

\begin{rmdtip}
I gave a presentation on workflows for backing data up as part of the
\href{https://slu-dss.github.io}{Data Science Seminar} series at
\href{https://slu.edu}{Saint Louis University}. You can easily view the
slides from that presentation on
\href{https://speakerdeck.com/chrisprener/protecting-your-data}{Speaker
Deck}, and you can download the session's materials from
\href{https://github.com/slu-dss/protectData}{GitHub}.
\end{rmdtip}

For this course in particular, it is \emph{imperative} that you backup
the data on your flash drive. A number of possibilities exist for
accomplishing this:

\begin{itemize}
\tightlist
\item
  Keep a local copy of your flash drive's files on your computer.
\item
  Keep a \texttt{.zip} archive of your files in a service like Dropbox
  or Google Drive. (Using a \texttt{.zip} archive will prevent issues
  with your \texttt{.git} repositories.)
\item
  Maintain a second flash drive copies of all of your files.
\end{itemize}

Whatever solution you select, make sure you regularly update your
backup. The more often you keep your backup archive updated, the less
stressful and disruptive losing your drive will be. This will likely be
a manual task, so follow the guidance above about creating a repeating
calendar event or to-do list task reminder.

\hypertarget{getting-help}{\chapter{Getting Help}\label{getting-help}}

One of the biggest challenges for students first learning tools like
\texttt{R}, ArcGIS, and LaTeX is dealing with the inevitable speed-bumps
and errors that come along with scientific computing. Remember, first
and foremost, that these tools are not consumer software. They do not
always ``just work'', to borrow a turn of phrase from
\href{https://en.wikipedia.org/wiki/Steve_Jobs}{Steve Jobs}. Learning
strategies for navigating issues when the software is most definitely
not working is therefore an important part of success.

One misconception that I think is important to confront is that data
analysts, software engineers, and others who appear to be experts may
indeed be very good at what they do, but they are equally skilled at
problem solving. This \href{https://www.xkcd.com/627/}{xkcd comic}
illustrates (a bit sarcastically!) the point:

\begin{center}\includegraphics[width=0.75\linewidth]{images/tech_support_cheat_sheet} \end{center}

Navigating challenges with data science may not be quite as easy
following the flowchart above, but there are definitely strategies for
working your way through errors and challenges in data science work.

\hypertarget{helping-yourself}{\section{Helping
Yourself}\label{helping-yourself}}

As I noted in \protect\hyperlink{zen-and-the-art-of-data-analysis}{Zen
and the Art of Data Analysis}, a key challenge of data science work is
mental. One of the traits I see frequently among students who are
confronted with errors is that they stop working and wait for office
hours or they immediately ask a question on Slack. Both office hours and
Slack are excellent options for getting help, but there are a few
strategies you should pursue first.

Before you doing anything else, however, \emph{take a deep breath} and
consider taking a break. When you being trying to fix the issue, check
the time. I have spent hours trying to fix some code in \texttt{R} or
mis-projected data in ArcGIS without success, and I have seen students
do the same. Give yourself an hour time limit to try the steps below
before you move on to constructing a reproducible example and asking for
help from others.

\subsection{Check Spelling}\label{check-spelling}

With \texttt{R}, the number one cause of errors that I see are
misspellings. If objects in the global environment or variable names
within a data frame are not spelled correctly (case matters!), you will
get an error that an object cannot be found. The same goes for package
and function names - they must be spelled 100\% correctly.

\subsection{Check Course Resources}\label{check-course-resources}

If the issue is one other students have come across as well, it is
likely to be discussed on Slack in the relevant channel. I may have also
updated some of the course handouts or the relevant lecture's course
webpage with details for how to address the concern. Check both Slack
and the webpage for updates before digging deeper. Check the topic index
on the relevant course website
(\href{https://slu-soc5650.github.io/topic-index/}{GIS topic index}) for
links to different lectures where concepts or processes were covered.

\subsection{Check Your Process}\label{check-your-process}

\texttt{R} functions and ArcGIS processes often have specific parameters
and requirements. If you have double checked your spelling and are sure
(100\% sure!) that spelling is not an issue, check to make sure that you
have followed all of the requirements of the workflow for the skill you
are stuck on. There are two different ways to go about doing this:

\begin{itemize}
\tightlist
\item
  Check the course handouts and lecture slides for the relevant
  processes. If you cannot remember where the concepts were introduced,
  check the topic index on the relevant course website
  (\href{https://slu-soc5650.github.io/topic-index/}{GIS topic index}).
  When I introduce processes, I often skip some (or many!) of the
  associated arguments and options, so the course materials are often
  easier to navigate than materials for other sources.
\item
  Search official documentation sources:

  \begin{itemize}
  \tightlist
  \item
    For \texttt{R}, check package documentation files on CRAN. These are
    linked to in the package index on the relevant course website
    (\href{https://slu-soc5650.github.io/package-index/}{GIS package
    index}). You can also use \href{https://cran.r-project.org}{CRAN's
    website} to search for package information.
  \item
    For ArcGIS, check ESRI's
    \href{http://desktop.arcgis.com/en/arcmap/}{official documentation
    files}. Make sure that you are looking at the help files for ArcGIS
    10.3!
  \item
    For Git and GitHub, check GitHub's
    \href{https://help.github.com}{help website}.
  \item
    For LaTeX, \href{https://www.sharelatex.com/}{ShareLaTeX} has an
    excellent set of documentation files on their
    \href{https://www.sharelatex.com/learn/Main_Page}{knowledge base}.
    \href{https://ctan.org}{CTAN}, the LaTeX package repository, also
    contains documentation files for all packages that can be searched.
  \end{itemize}
\end{itemize}

Use these resources to try and narrow down what might be causing your
issue. Be mindful that the root cause of an error may be several steps
back in your workflow. Walk back through your process to make sure your
initial steps are not the cause of the error.

\subsection{Cast a Wider Net}\label{cast-a-wider-net}

If none of these resources are sufficient, there are a few other options
for seeking out guidance. When you search the following sites, it is
often a good idea to search based on the specific error you are getting.
Take out any aspects of the error that are specific to you, like a file
path in ArcGIS, a file name, or a variable name. One set of options to
search are the wealth of web resources that are available for some of
the tools we use:

\begin{itemize}
\tightlist
\item
  For \texttt{R}, check out
  \href{https://www.rstudio.com/resources/cheatsheets/}{RStudio's
  cheatsheets} and \href{https://community.rstudio.com}{RStudio's
  community forums}. If the package is part of the \texttt{tidyverse},
  check the \href{http://tidyverse.org}{website} as well as
  \href{http://r4ds.had.co.nz}{R for Data Science}. Other packages have
  their own websites as well. For all of these resources, links are
  provided in the package index on the relevant course website
  (\href{https://slu-soc5650.github.io/package-index/}{GIS package
  index}).
\item
  For LaTeX, there is a \href{https://en.wikibooks.org/wiki/LaTeX}{LaTeX
  wikibook} with some excellent resources.
\end{itemize}

Another resource is \href{https://stackexchange.com}{Stack Exchange}, a
network of online communities on a variety of topics including:

\begin{itemize}
\tightlist
\item
  \href{https://stackoverflow.com}{Stack Overflow} for \texttt{R}, Git,
  and GitHub - search using tags like \texttt{{[}r{]}},
  \texttt{{[}ggplot2{]}}, \texttt{{[}dplyr{]}}, \texttt{{[}git{]}},
  \texttt{{[}github{]}}, etc.
\item
  \href{https://gis.stackexchange.com}{Geographic Information Systems}
  for GIS - search using the \texttt{{[}arcgis-desktop{]}} tag
\item
  \href{https://tex.stackexchange.com}{TeX} for LaTeX
\end{itemize}

Stack Exchange may have posts that address the issue or question you
have. However, the match may only be partial and may require additional
modification or tinkering to solve your specific concern. You may spend
just as much time trying to get a Stack Exchange solution to work as you
would waiting for a response on Slack, so proceed with caution if you
decide to go this route.

Finally, if you have exhausted these other options, a Google search may
be effective. This may help you identify GitHub issues, blogs, and other
online tutorials that can help address whatever roadblock you have run
into. Try searching first with double quotes around the main body of the
error message's text. If nothing comes up, try searching without the
double quotes. Search strings that include \texttt{R} package names or
specific processes in ArcGIS are sometimes helpful for narrowing down a
large amount of search results, especially if those results are not
specific to the tool you are using. The same warning for Stack Exchange
also exists for Google, however. You may find imperfect matches for your
problem that take considerably more tinkering to implement.

\hypertarget{how-to-seek-help}{\section{How to Seek
Help}\label{how-to-seek-help}}

If all else fails and the strategies for
\protect\hyperlink{helping-yourself}{Helping Yourself} have not yielded
a solution, it is time to ask for help! Before you head to office hours
or Slack, you will want to construct a \textbf{reproducible example}.

\subsection{What is your question?}\label{what-is-your-question}

Start with a basic step - narrow down what your question is. Neither ``I
am getting an error'' or ``This isn't working'' are effective questions.
What exactly is causing the error? What context does it appear in? To
borrow from the examples below, a good question might be:

\begin{quote}
I am trying to calculate descriptive statistics for an entire data frame
using the \texttt{mean()} function but am getting and error. What might
be the cause of the error?
\end{quote}

\begin{quote}
I am trying to create a thematic choropleth map in ArcGIS, but when I
try and select my variable from the dropdown menu in the symbology tab
under layer properties, the menu is empty. Why are all of the variables
missing?
\end{quote}

\begin{quote}
I am trying to make my text bold in LaTeX, but the text is not rendering
with bold font. I am also getting an error that says ``Undefined control
sequence.'' What is missing from my document to create bold font?
\end{quote}

Be specific about what your issue is, and then provide a reproducible
example that illustrates what you are asking about.

\subsection{What is a reproducible
example?}\label{what-is-a-reproducible-example}

A reproducible example, or reprex, is a term we'll borrow from the
\texttt{R} ecosystem. It was coined by
\href{https://twitter.com/romain_francois/status/530011023743655936}{Roman
FranÃ§ois} and has been enshrined in the
\href{http://reprex.tidyverse.org}{\texttt{reprex} package}, which I'll
describe below. The goal for a reprex is to strip down the process you
have used to the minimal number of steps needed to replicate the error.
This means using the fewest steps and data sources possible. Cut out
anything that does not directly contribute to causing the error when
making your reprex.

I have often found that the process of making a reprex actually helps
isolate the cause of the problem. For instance, it may become clear that
a specific step is causing an issue. Even if you are not sure how to fix
the problem, having narrowed it down can be immensely helpful. If you
can use built-in data in \texttt{R} to create the reprex, or at least
example data from the course, that may also help you identify whether
the issue is with the process itself or something that is idiosyncratic
to the data you are using. Using built-in data from \texttt{R} should be
the default for any reprex you create, \emph{unless assignment data are
the cause of your issue}.

\subsection{Creating a reprex}\label{creating-a-reprex}

Creating reproducible examples will differ slightly based on what you
are trying to get help on.

\subsubsection{\texorpdfstring{\texttt{R}}{R}}\label{r}

To create a reprex in \texttt{R}, you will need to install the
\href{http://reprex.tidyverse.org/}{\texttt{reprex} package}. It is part
of the \href{https://www.tidyverse.org}{tidyverse} but it is not
installed when the \texttt{tidyverse} package is installed, so you will
need to install it separately:

\begin{Shaded}
\begin{Highlighting}[]
\KeywordTok{install.packages}\NormalTok{(}\StringTok{"reprex"}\NormalTok{)}
\end{Highlighting}
\end{Shaded}

Once you have it loaded (use the \texttt{library()} function), create a
minimal example of the necessary functions that get to you to the error
you are confronting. Make sure to include the \texttt{library()}
functions for all packages your example depends on (except for
\texttt{reprex}). Write the example in a \texttt{.R} script file
(\texttt{File\ \textgreater{}\ New\ File\ \textgreater{}\ R\ Script}).
For example, one might be struggling with calculating the mean of each
variable in a data frame:

\begin{Shaded}
\begin{Highlighting}[]
\KeywordTok{library}\NormalTok{(ggplot2)}

\CommentTok{# assign data to data frame}
\NormalTok{data <-}\StringTok{ }\NormalTok{mpg}

\CommentTok{# attempt to calculate mean}
\KeywordTok{mean}\NormalTok{(data)}
\end{Highlighting}
\end{Shaded}

The last of the three functions above will return this error in your
\texttt{R} session:

\begin{Shaded}
\begin{Highlighting}[]
\OperatorTok{>}\StringTok{ }\KeywordTok{mean}\NormalTok{(data)}
\NormalTok{[}\DecValTok{1}\NormalTok{] }\OtherTok{NA}
\NormalTok{Warning message}\OperatorTok{:}
\NormalTok{In }\KeywordTok{mean.default}\NormalTok{(data) }\OperatorTok{:}\StringTok{ }\NormalTok{argument is not numeric or logical}\OperatorTok{:}\StringTok{ }\NormalTok{returning }\OtherTok{NA}
\end{Highlighting}
\end{Shaded}

With the three functions written in a \texttt{.R} script, highlight all
seven lines of code (the three functions, both comments, and both white
space lines) and copy them to your clipboard
(\texttt{Edit\ \textgreater{}\ Copy}). Then call the \texttt{reprex()}
function. Markdown formatted text that weaves both the functions and
their output together will appear in the viewer tab:

\begin{center}\includegraphics[width=0.5\linewidth]{images/reprex} \end{center}

It will also be available on your clipboard so that you can copy and
paste it into Slack or another venue that accepts Markdown syntax (like
GitHub). If your reprex contains image output, such as a plot or a map,
it will be automatically uploaded to imgur and a link will be embedded
in your Markdown syntax. For example, say we had a question about the
following code:

\begin{Shaded}
\begin{Highlighting}[]
\KeywordTok{library}\NormalTok{(ggplot2)}

\CommentTok{# assign data to data frame}
\NormalTok{data <-}\StringTok{ }\NormalTok{mpg}

\CommentTok{# plot highway mpg}
\KeywordTok{ggplot}\NormalTok{(}\DataTypeTok{data =}\NormalTok{ data, }\DataTypeTok{mapping =} \KeywordTok{aes}\NormalTok{(}\DataTypeTok{x =}\NormalTok{ hwy)) }\OperatorTok{+}\StringTok{ }
\StringTok{  }\KeywordTok{geom_histogram}\NormalTok{()}
\end{Highlighting}
\end{Shaded}

Once we copy the above code and render it using \texttt{reprex()}, it
will return the following output:

\begin{Shaded}
\begin{Highlighting}[]
\KeywordTok{library}\NormalTok{(ggplot2)}

\CommentTok{# assign data to data frame}
\NormalTok{data <-}\StringTok{ }\NormalTok{mpg}

\CommentTok{# plot highway mpg}
\KeywordTok{ggplot}\NormalTok{(}\DataTypeTok{data =}\NormalTok{ data, }\DataTypeTok{mapping =} \KeywordTok{aes}\NormalTok{(}\DataTypeTok{x =}\NormalTok{ hwy)) }\OperatorTok{+}\StringTok{ }
\StringTok{  }\KeywordTok{geom_histogram}\NormalTok{()}
\CommentTok{#> `stat_bin()` using `bins = 30`. Pick better value with `binwidth`.}

\OperatorTok{!}\NormalTok{[](https}\OperatorTok{:}\ErrorTok{//}\NormalTok{i.imgur.com}\OperatorTok{/}\NormalTok{8hiC7od.png)}
\end{Highlighting}
\end{Shaded}

The \texttt{!{[}{]}(hyperlink)} syntax will allow an image of your plot
to appear below the code.

The \href{http://reprex.tidyverse.org}{\texttt{reprex} package website}
has some great resources, including a
\href{http://reprex.tidyverse.org}{basic overview}, some
\href{http://reprex.tidyverse.org/articles/reprex-dos-and-donts.html}{reprex
do's and don'ts}, and a
\href{http://reprex.tidyverse.org/articles/articles/magic-reprex.html}{detailed
article} introducing the package's functionality.

\subsubsection{ArcGIS}\label{arcgis}

Creating a reprex in ArcGIS is not as straightforward since there is not
a dedicated tool for doing so like there is in \texttt{R}. Reprex
creation is complicated by the fact that many steps you will be taking
are manual. Nevertheless, it is possible to create a repex. Follow these
steps:

\begin{enumerate}
\def\labelenumi{\arabic{enumi}.}
\tightlist
\item
  In a new map document, load the minimum number of shapefiles needed to
  illustrate the issue you are having. Note where the shapefiles are
  available (in the course data release?) and what their names are.
\item
  Note what the coordinate system of the data frame is set to.
\item
  Provide notes for each step that gets you to your question or error.
\item
  Take a \href{https://www.take-a-screenshot.org}{screenshot} of the
  error or the window you have a question about.
\end{enumerate}

For example, a reprex of a question in ArcGIS could look like the
following:

\begin{verbatim}
1. I have a single map shapefile open in a new map document. The shapefile is the St. Louis census tracts shapefile from the example data in the course data release.
2. The coordinate system is Missouri State Plane East (Feet)
3. When I right click on the shapefile, I click on Properties and then the Symbology tab
4. Attached is a screenshot of what the symbology tab looks like for these data.
\end{verbatim}

\subsubsection{LaTeX}\label{latex}

Like ArcGIS, there is no specific tool for creating a reprex using
LaTeX. The LaTeX community does have, however, a long tradition of
creating ``minimal working examples'', which are similar to reprexs.
Follow these general steps:

\begin{enumerate}
\def\labelenumi{\arabic{enumi}.}
\tightlist
\item
  Create a new LaTeX project. Use the
  \texttt{\textbackslash{}documentclass\{article\}} if you are using
  something different.
\item
  Only include packages in the preamble that are \textbf{directly}
  related to the question or issue you have.
\item
  Skip creating a title block
\item
  Provide just enough body text in your LaTeX document to illustrate the
  issue.
\end{enumerate}

A repex for LaTeX might look something like this:

\begin{Shaded}
\begin{Highlighting}[]
\BuiltInTok{\textbackslash{}documentclass}\NormalTok{\{}\ExtensionTok{article}\NormalTok{\}}

\KeywordTok{\textbackslash{}begin}\NormalTok{\{}\ExtensionTok{document}\NormalTok{\}}

\FunctionTok{\textbackslash{}textbold}\NormalTok{\{Foo bar.\} Spam and eggs.}

\KeywordTok{\textbackslash{}end}\NormalTok{\{}\ExtensionTok{document}\NormalTok{\}}
\end{Highlighting}
\end{Shaded}

Also provide a written description of what is wrong (such as ``the text
is not being rendered as bold'') and, if helpful, a
\href{https://www.take-a-screenshot.org}{screenshot} of your output.
There is a great
\href{https://tex.meta.stackexchange.com/questions/228/ive-just-been-asked-to-write-a-minimal-example-what-is-that}{overview
on Stack Exchange} of how to write a reprex for LaTeX. If you are using
ShareLaTeX, also take a look at the error log and take a
\href{https://www.take-a-screenshot.org}{screenshot} of the relevant
error message. If you are using another LaTeX application, provide the
text of your error message instead.

\subsubsection{Other Tools}\label{other-tools}

For other tools we learn, such as Markdown and GitHub, you want to
follow the spirit of the reprex file. Try to recreate your issue outside
of the context of your assignment (this may not be possible for GitHub),
and provide a detailed walk-through of the steps that you took to get
where you are. For Markdown syntax, provide an example of the syntax you
are using that recreates the issue or question. For GitHub, provide a
\href{https://www.take-a-screenshot.org}{screenshot} of the relevant
error message.

\subsection{\texorpdfstring{``I don't think I can make a
reprex!''}{I don't think I can make a reprex!}}\label{i-dont-think-i-can-make-a-reprex}

I am 99\% sure that you can! In nearly every situation I have seen
students in, creating a reprex is possible. Even if the error is
idiosyncratic to your computer or your data, you can absolutely clarify
the context within which the error appears and minimize the amount of
data, code, and other information in your \texttt{R} code or your map
document. For the less than 1\% of scenarios where a reprex is not
possible, the process of writing a question, clarifying the context and
steps you took to get there, and producing an example of the error will
still make it easier for me to help you.

\subsection{\texorpdfstring{``Isn't this a lot of
work?''}{Isn't this a lot of work?}}\label{isnt-this-a-lot-of-work}

Well, yes, it does require some extra effort. This effort is almost
always worth it, however. In some cases, the time it takes you to
produce the repex leads you to the answer on your own, which is part of
the problem solving process that this class is designed to foster. Even
when this does not happen, making reprex informed inquires is a
technique that you will be able to take with you at the end of the
semester. Even if you are not working in a technical setting, being able
to structure clear, concise questions about a process is a valuable
skill!

Finally, creating a reprex saves you time in the long run. When I get
vague questions, it often takes some experimenting on my part to
reproduce the error. If you send me a question with a reproducible
error, you cut out that experimentation time on my end and I can get
right to answering your question. Likewise, students often come to
office hours without an example of their issue ready to go and hope that
I can conjure in my mind the scenario they are describing. Despite my
best efforts, I am usually unable to do so and ask students to reproduce
the error during office hours. If you come to office hours with a
reprex, we can get to answering your question right away!

\section{Where to Seek Help}\label{where-to-seek-help}

Once you have tried \protect\hyperlink{helping-yourself}{Helping
Yourself} and have gone through the steps outlined in
\protect\hyperlink{how-to-seek-help}{How to Seek Help} (i.e.~made a
reprex), it is time to ask your question. There are a number of
different places that you can pose questions. The sections below outline
these and suggest some ways to make your question most effective.

\subsection{Internal Venues}\label{internal-venues}

Within the confines of the course, the two best places to ask questions
are on Slack and during office hours. When asking a question on Slack,
please consider doing so in a public channel. This helps others learn
from the question that you have. The only course-related questions that
are not appropriate for Slack are those that reference specific parts of
a problem set or the final project. However, if you are creating
reproducible examples, your questions should not be that specific even
if they ultimately are about a homework assignment. If you are not sure
whether the question is appropriate or not for a public channel, or just
would prefer not to ask your question out in the open, feel free to send
me a
\href{https://get.slack.help/hc/en-us/articles/212281468-Direct-messages-and-group-DMs}{direct
message on Slack}.

When you pose a question on Slack, it should contain three or four
pieces of information:

\begin{enumerate}
\def\labelenumi{\arabic{enumi}.}
\tightlist
\item
  The question itself - what are you hoping to get help with?
\item
  A reproducible example - give as many details as you need to clearly
  illustrate the question
\item
  A \href{https://www.take-a-screenshot.org}{screenshot} or image output
  that illustrates your reprex
\item
  What you've tried - lay out the steps you took to quickly (``I've
  checked the spelling, gone through the Lecture 03 documents, looked at
  the \texttt{dplyr} website, and have done a quick Google search.'')
\end{enumerate}

Post your reprex as a
\href{https://get.slack.help/hc/en-us/articles/204145658-Create-a-snippet}{snippet}
in Slack by:

\begin{enumerate}
\def\labelenumi{\arabic{enumi}.}
\tightlist
\item
  Clicking the plus sign on the left side of the message box
\item
  Selecting \textbf{Code or text snippet}
\item
  Filling out the pop-up window
\end{enumerate}

If you are posting a reprex from \texttt{R}, remove the three backticks
and the letter \texttt{r} from the first line as well as the three
backticks from the bottom line. If you are including an image hyperlink
created by the \texttt{reprex} package, remove that from the code
snippet and paste it into Slack separately. A good question on Slack
should look like this:

\begin{center}\includegraphics[width=0.9\linewidth]{images/slackQuestion} \end{center}

This same general process holds for asking questions in person - come
ready with a solid question, a reproducible example, and be ready to
pull it up on your computer or a lab computer.

\subsection{External Venues}\label{external-venues}

There are two good places to ask questions external to the course as
well. For questions related to RStudio, R Markdown, and the
\href{http://tidyverse.org}{tidyverse}, RStudio maintains a web forum
called \href{https://community.rstudio.com}{RStudio Community}. If you
are posting there, you can use \texttt{reprex()} to generate Markdown
formatted reprexs.

Another place to post questions in on one of the relevant
\href{https://stackexchange.com}{Stack Exchange} communities:

\begin{itemize}
\tightlist
\item
  \href{https://stackoverflow.com}{Stack Overflow} for \texttt{R}, Git,
  and GitHub - post using tags like \texttt{{[}r{]}},
  \texttt{{[}ggplot2{]}}, \texttt{{[}dplyr{]}}, \texttt{{[}git{]}},
  \texttt{{[}github{]}}, etc.
\item
  \href{https://gis.stackexchange.com}{Geographic Information Systems}
  for GIS - post using the \texttt{{[}arcgis-desktop{]}} tag
\item
  \href{https://tex.stackexchange.com}{TeX} for LaTeX
\end{itemize}

Before you post, search thoroughly to make sure that your question has
not already been answered. Stack Exchange has strong norms about how to
post appropriately. You can descriptions of what makes a good post
\href{https://codereview.stackexchange.com/help/how-to-ask}{here} and
\href{https://stackoverflow.com/help/how-to-ask}{here}. You can also
find a description of
\href{https://stackoverflow.com/help/dont-ask}{what not to ask}. If you
are going to post on Stack Overflow, the \texttt{reprex()} function can
be modified to produce well-formatted output specific to that site by
adding the \texttt{venue} argument, as in
\texttt{reprex(venue\ =\ "so")}.

Of the two sites, I find \href{https://community.rstudio.com}{RStudio
Community} to be a friendlier place that is more relaxed than Stack
Overflow and its cousins. However, Stack Exchange communities have much
larger user bases to draw from.

\part{Data Science Toolkit}\label{part-data-science-toolkit}

\chapter{Opinionated Tools}\label{opinionated-tools}

The \protect\hyperlink{intro}{Introduction} to this text describes
opinionated analysis development as a key element that both
\href{https://slu-soc5650.github.io}{Introduction to Geographic
Information Science (SOC 4650/5650)} and
\href{https://slu-soc5050.github.io}{Quantitative Analysis: Applied
Inferential Statistics (SOC 4930/5050)} are built around. Parker's
(2017) term is a reference to opinionated software, which is designed
with a strong set of guiding principles that strongly encourages users
to follow certain processes (Eccles 2015). When possible, we'll use
opinionated applications or processes that support our larger goals of
opinionated analysis development. This section introduces a number of
the key tools that we use to accomplish data science work with social
and spatial data.

\hypertarget{markdown}{\chapter{Markdown}\label{markdown}}

Markdown is a simple
\href{https://en.wikipedia.org/wiki/Markup_language}{markup language}.
Markup languages are used to give computer programs directions on how
particular blocks of text should be processed. Markdown was developed in
2004 by writer and developer \href{http://daringfireball.net}{John
Gruber}. Gruber describes Markdown on his
\href{http://daringfireball.net/projects/markdown/}{website}:

\begin{quote}
Markdown is intended to be as easy-to-read and easy-to-write as is
feasible.
\end{quote}

\begin{quote}
Readability, however, is emphasized above all else. A Markdown-formatted
document should be publishable as-is, as plain text, without looking
like it's been marked up with tags or formatting instructions. While
Markdown's syntax has been influenced by several existing text-to-HTML
filters --- including Setext, atx, Textile, reStructuredText, Grutatext,
and EtText --- the single biggest source of inspiration for Markdown's
syntax is the format of plain text email.
\end{quote}

\begin{quote}
To this end, Markdown's syntax is comprised entirely of punctuation
characters, which punctuation characters have been carefully chosen so
as to look like what they mean. E.g., asterisks around a word actually
look like \emph{emphasis}. Markdown lists look like, well, lists. Even
blockquotes look like quoted passages of text, assuming you've ever used
email\ldots{}
\end{quote}

\begin{quote}
\ldots{}Markdown's syntax is intended for one purpose: to be used as a
format for writing for the web.
\end{quote}

Markdown is utilized to varying degrees by many of the data science
tools we'll use in both courses, including RStudio, GitHub, and Slack.
In all three applications, Markdown provides a straightforward way to
format and stylize plain text files. Markdown therefore gives us the
best of two worlds - text files can be organized and formatted as in
\href{https://en.wikipedia.org/wiki/WYSIWYG}{WYSIWYG} editors like
Microsoft Word, but they remain plain text files that are accessible in
a variety of computing environments and do not depend on proprietary
applications.

\section{Document Organization}\label{document-organization}

There are two principle means for organizing Markdown documents -
headings of varying size and paragraph breaks.

\subsection{Headings}\label{headings}

Markdown contains six heading levels. Headings are identified with
\texttt{\#} symbols and a space that separates them from from the
heading text.

\textbf{Input:}

\begin{Shaded}
\begin{Highlighting}[]
\FunctionTok{# This is the largest heading}
\FunctionTok{## This is the second largest heading}
\FunctionTok{### This is the third largest heading}
\FunctionTok{#### This is the fourth largest heading}
\FunctionTok{#### This is the second smallest heading}
\FunctionTok{###### This is the smallest heading}
\end{Highlighting}
\end{Shaded}

\textbf{Output:}

\begin{flushleft}\includegraphics[width=0.5\linewidth]{images/markdownHead} \end{flushleft}

\subsection{New Paragraphs}\label{new-paragraphs}

Leave a blank line between two paragraphs to create a break.

\textbf{Input:}

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{Lorem ipsum dolor sit amet, consectetur adipiscing elit, sed do eiusmod tempor }
\NormalTok{incididunt ut labore et dolore magna aliqua. Quam pellentesque nec nam aliquam }
\NormalTok{sem et tortor consequat. Auctor urna nunc id cursus metus. Eleifend mi in }
\NormalTok{nulla posuere. Facilisis sed odio morbi quis. Nibh nisl condimentum id venenatis. }
\NormalTok{Lectus nulla at volutpat diam ut venenatis. }

\NormalTok{Pretium lectus quam id leo in vitae. Neque vitae tempus quam pellentesque nec nam }
\NormalTok{aliquam. Curabitur gravida arcu ac tortor. Arcu risus quis varius quam quisque id }
\NormalTok{diam. Viverra aliquet eget sit amet tellus cras adipiscing. Tellus molestie nunc }
\NormalTok{non blandit massa enim nec. Tempus imperdiet nulla malesuada pellentesque elit eget. }
\NormalTok{Non blandit massa enim nec. Sed risus pretium quam vulputate dignissim suspendisse }
\NormalTok{in est ante.}
\end{Highlighting}
\end{Shaded}

\textbf{Output:}

Lorem ipsum dolor sit amet, consectetur adipiscing elit, sed do eiusmod
tempor incididunt ut labore et dolore magna aliqua. Quam pellentesque
nec nam aliquam sem et tortor consequat. Auctor urna nunc id cursus
metus. Eleifend mi in nulla posuere. Facilisis sed odio morbi quis. Nibh
nisl condimentum id venenatis. Lectus nulla at volutpat diam ut
venenatis.

Pretium lectus quam id leo in vitae. Neque vitae tempus quam
pellentesque nec nam aliquam. Curabitur gravida arcu ac tortor. Arcu
risus quis varius quam quisque id diam. Viverra aliquet eget sit amet
tellus cras adipiscing. Tellus molestie nunc non blandit massa enim nec.
Tempus imperdiet nulla malesuada pellentesque elit eget. Non blandit
massa enim nec. Sed risus pretium quam vulputate dignissim suspendisse
in est ante.

\section{Working with Text}\label{working-with-text}

Markdown provides a number of tools for working with and stylizing text.
These include options for bold and italicized text, adding code blocks,
quoting text, and creating bulleted and enumerated lists.

\subsection{Styling Text}\label{styling-text}

Text can be styled using bold and italics To create italicized text,
wrap your text with a single asterisk \texttt{*}. To create bold text,
wrap your text with double asterisks \texttt{**}.

\textbf{Input:}

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{*This is an italicized sentence.*}

\NormalTok{**This is a bolded sentence.**}
\end{Highlighting}
\end{Shaded}

\textbf{Output:}

\emph{This is an italicized sentence.}

\textbf{This is a bolded sentence.}

\subsection{Quoting Text}\label{quoting-text}

Quoting text (which I have used above to illustrate examples) is done
with a greater then symbol (\texttt{\textgreater{}}).

\textbf{Input:}

\begin{verbatim}
> This is quoted text.
\end{verbatim}

\textbf{Output:}

\begin{quote}
This is quoted text.
\end{quote}

\subsection{Quoting Code}\label{quoting-code}

There are two types of code quotes in Markdown. In-line quotes, which
are included in a sentence, are wrapped in single backticks:
\textgreater{} Use the \texttt{describe} command to list variables in
\texttt{R}

To include code blocks, which are better for including the full syntax
of particular commands and their output, use triple backticks:

\begin{verbatim}
. describe make price mpg

              storage   display    value
variable name   type    format     label      variable label
--------------------------------------------------------------------------------
make            str18   %-18s                 Make and Model
price           int     %8.0gc                Price
mpg             int     %8.0g                 Mileage (mpg)
\end{verbatim}

Note how the word `Stata' is written after the first set of triple
backticks. This is an indicator for GitHub that the code is written in
Stata's programming language. By including this, GitHub can apply some
syntax highlighting to your files. This makes them easier to read.

\subsection{Links}\label{links}

In Markdown, adding hyperlinks is a two step process. The text that you
want to have hyperlinked is written first and is wrapped in brackets
\texttt{{[}{]}}. After this, you include the URL wrapped in parentheses
\texttt{()}. This is an example of including in-line hyperlinks:

\begin{quote}
The course \href{https://github.com/slu-soc5050}{website} is hosted
using the service \href{https://github.com}{GitHub}.
\end{quote}

\subsection{Embedding Images}\label{embedding-images}

Within the directory that contains your Markdown file, create a
subdirectory called \texttt{Output}. Save all images for a particular
assignment there. In your main assignment Markdown file, include a
hyperlink reference:

Note how, instead of including text to be hyperlinked, we suppress this
aspect of the syntax by using an exclamation point \texttt{!}.

\subsection{Simple Lists}\label{simple-lists}

Bulleted lists are indicated in Markdown using the dash \texttt{-} or a
single asterisk \texttt{*}:

\begin{quote}
\begin{itemize}
\tightlist
\item
  mean
\item
  median
\item
  mode
\item
  variance
\item
  standard deviation
\end{itemize}
\end{quote}

Enumerated lists are created by preceding each line with the appropriate
number:

\begin{quote}
\begin{enumerate}
\def\labelenumi{\arabic{enumi}.}
\tightlist
\item
  calculate the mean
\item
  calculate the variance
\item
  calculate the standard deviation
\end{enumerate}
\end{quote}

You can create more complex lists by preceding a line with two single
spaces. You can also combine bulleted and enumerated lists when using
this approach.

\section{GitHub Markdown}\label{github-markdown}

These are specific to what is called GitHub Markdown - there are some
subtle differences in the way GitHub uses Markdown formatting.

\subsection{Styling Text}\label{styling-text-1}

Text can be styled using bold, italics, and strikethroughs. To create
italicized text, wrap your text with a single asterisk \texttt{*\ *}. To
create bold text, wrap your text with double asterisks \texttt{**\ **}.
To create strike-through text, wrap your text with two tildes
\texttt{\textasciitilde{}\textasciitilde{}\ \textasciitilde{}\textasciitilde{}}.

\begin{quote}
\sout{This is a sentence with strikethrough text}
\end{quote}

\subsection{Tables}\label{tables}

\subsection{Task Lists}\label{task-lists}

If you want to create task lists on GitHub, you can include brackets
separated by a space before each list item \texttt{{[}\ {]}}. Completed
tasks include an \texttt{x} in place of the space \texttt{{[}x{]}}.
These task lists are interactive - when published on GitHub, you can
click on the resulting checkboxes to toggle them between complete /
incomplete.

\begin{quote}
\begin{enumerate}
\def\labelenumi{\arabic{enumi}.}
\tightlist
\item
  {[}x{]} calculate the mean
\item
  {[} {]} calculate the variance
\item
  {[} {]} calculate the standard deviation
\end{enumerate}
\end{quote}

\subsection{Mentioning Other GitHub
Users}\label{mentioning-other-github-users}

If you want to mention me or one of your classmates in a comment,
include the \texttt{@} symbol before their username:

\begin{quote}
Hey \citet{chris-prener}, thanks for the feedback. I made the changes to
lines 40 and 41.
\end{quote}

Once the document is uploaded to GitHub, the username will render as a
hyperlink and the user will be alerted.

\hypertarget{basic-git}{\chapter{Basic Git}\label{basic-git}}

Much of our interaction this semester outside of class will utilize
GitHub.com (or just ``GitHub''). GitHub is a web service that is a
social network for programmers, developers, data scientists,
researchers, and academics. It is also a tool for collaborating on
projects, especially projects that involve writing code.

We'll use GitHub as an alternative to Blackboard, the \emph{course
management system} that students are typically familiar with. Course
materials will be posted there, and GitHub's features will allow you to
copy them and keep them updated as changes are made. You'll also use
GitHub to submit assignments for grading, and we'll give you feedback
and grades via GitHub as well.

\section{Git Basics}\label{git-basics}

\subsection{Git}\label{git}

GitHub is a web application that utilizes
\href{https://git-scm.com}{Git}:

\begin{quote}
Git is a free and open source distributed version control system
designed to handle everything from small to very large projects with
speed and efficiency.
\end{quote}

Essentially, Git is a project-wide system for tracking changes to files.
Think of it as Microsoft office's track changes feature on steroids -
every change to every file in a directory is tracked. A directory that
has tracking enabled with Git is called a \textbf{repository} or
``repo'' in Git-lingo.

You do no need to host files online to use Git. If you have a project
saved locally (say, a doctoral thesis), you could utilize Git to version
control that project without ever uploading it to the Internet. However,
Git integrates seemlessly with \textbf{remote} repositories. The most
well-known host of remote repos is
\protect\hyperlink{github.com}{GitHub.com}.

Beyond ``repositories'', there are a few additional terms that are
specific to Git and that are helpful to know:

\begin{itemize}
\tightlist
\item
  \textbf{Clone}: Make an identical copy of a repository on your local
  hard drive.
\item
  \textbf{Commit}: Approve any changes you have made to a repository.
\item
  \textbf{Sync}: For cloned repositories, files that have been changed
  need to be synced or \textbf{pushed} to GitHub.com after they are
  committed.
\end{itemize}

For our purposes, this is just about all you need to know about Git. If
you want to learn more, \href{https://git-scm.com/about}{Git's `About'
page} is a great place to start.

\hypertarget{github.com}{\subsection{GitHub.com}\label{github.com}}

GitHub is a web service that can host projects using Git's version
tracking. It is widely used by programmers, software developers, data
scientists, and academics to host and collaborate projects.

GitHub is an excellent way to backup files for a project since you can
``sync'' changes made to a repository up to GitHub's servers. It is also
an excellent way to collaborate on files with colleagues while also
using Git's version tracking. Repositories can be either public (like
all of the repos for our seminar) or private, which means that only
people who have been given access to can view the contents of the repo.
Private repos require an upgraded account, which retails for \$7/month.

Students can get access to GitHub's paid services for free, however, by
signing up for a \href{https://education.github.com}{free student
account}. This will give you access to private repositories for as long
as you are a student. GitHub also provides this free upgrade service to
educators, which is how our classes have private repositories.

\section{The Workflow of Git and
GitHub}\label{the-workflow-of-git-and-github}

The typical approach to versioning for many students is manual. For a
hypothetical class response paper, it might look something like this:

\begin{center}\includegraphics[width=0.5\linewidth]{images/gitFlow01} \end{center}

The author made an initial copy of the paper, and then used a haphazard
and inconsistent approach for naming subsequent copies of the paper. We
can presume that changes were made in a linear fashion, though it is
easy to make changes to, say, \texttt{First\ Response\ Paper\ 2.doc}
after \texttt{First\ Response\ Paper\ 3.doc} has been created and
edited.

\subsection{Commits}\label{commits}

Instead of saving copies of their hypothetical paper, a student using
GitHub could write the paper in a single document, \textbf{commiting}
their changes as they progress to take ``snapshots'' of their progress.
These snapshots contain information on changes the student has made,
tracked line-by-line. So, at each point in which a new document would
have been created in the typical workflow, a student using GitHub would
simply \textbf{commit} their changes:

\begin{center}\includegraphics[width=0.95\linewidth]{images/gitFlow02} \end{center}

Git provides a number of useful features beyond simply tracking changes.
Each commit is accompanied a \textbf{message}. These messages must have
a short summary that appears on GitHub and can also have a longer
description that can be used to describe in detail what changes are
being applied with a specific commit:

\begin{center}\includegraphics[width=0.95\linewidth]{images/gitFlow03} \end{center}

Messages, combined with the changes that are tracked, allow users to
trace the development of a single document or an entire project
overtime:

\begin{center}\includegraphics[width=0.95\linewidth]{images/gitFlow04} \end{center}

This means that, if necessary, the project can also be rolled back to an
earlier period. Finally, users can \textbf{sync} their commits with
GitHub.com, hosting their changes and their data in a way that protects
them against certain types of computer failures and also allowing them
to easily share their work with others.

\subsection{More About Repositories}\label{more-about-repositories}

Users of GitHub.com adhere to a couple of norms with their repositories
that are worth knowing about. Repositories cannot have spaces in their
names (much like objects in \texttt{R}), so the naming conventions that
we will discuss in relation to \texttt{R} this semester all apply to
GitHub as well!

Public GitHub repositories also contain (typically) at least three core
files:

\begin{enumerate}
\def\labelenumi{\arabic{enumi}.}
\item
  A \textbf{license} file - since the data is out there for public
  consumption, it is important to think about how that data is licensed.
  The norm among GitHub users has been to use open source licenses,
  which let others edit and adapt your work. There are a range of
  \href{http://choosealicense.com}{licenses} that are commonly used on
  GitHub.
\item
  A \textbf{README} file - this describes the purpose and content of the
  project.
\item
  A \textbf{.gitignore} file - this stops certain types of files from
  being swept up by GitHub when a user syncs their files with a server.
\end{enumerate}

When you clone your repositories, you will be prompted to save them on
your computer. There are a number of ways in which this process can
introduce sources for trouble down the road. The principle way that I
have seen students run into problems with GitHub is by storing
repositories on cloud storage services like Dropbox or Google Drive. In
order to avoid any issues, I advise against storing GitHub repositories
in an area of your computer that syncs with a cloud service.

\section{GitHub Issues}\label{github-issues}

GitHub has a powerful tool for interaction called
\href{https://help.github.com/articles/about-issues/}{Issues}. These can
be accessed by opening a repository and then clicking on the ``Issues''
tab. Issues can be ``opened'' by anyone with access to the repository.
They allow for a conversation to occur in the form of messages posted
within the Issue itself. Files can be attached to Issues, and the
messages can contain Markdown formatting. Once the conversation is
complete, issues can be marked as ``closed'', which moves them into a
secondary view on the website so that they are archived.

We'll use issues for both assignment feedback and grading. Please keep
up with issues are they appear, and feel free to follow-up with specific
questions about your grade or the assignment feedback in the Issue
conversation. Once you are satisfied, please mark the issue as closed.

\section{GitHub Desktop Application}\label{github-desktop-application}

\href{https://desktop.github.com}{GitHub Desktop} is a tool that allows
you to easily clone repositories hosted on GitHub, commit changes to
them, and then sync those changes up to the website. You can also create
new repositories, however this is not task you will have to do this
semester. GitHub Desktop is not a fully functional desktop version of
GitHub. For our purposes, it is important to note that the Desktop
application will not let you easily identify when repositories have been
updated by other users, view Wikis associated with repositories, or view
Issues.

\section{Learning More}\label{learning-more}

GitHub has a
\href{https://help.github.com/articles/good-resources-for-learning-git-and-github/}{resources
page} with links to websites that are great for helping you learn more
about how Git and GitHub work! The next chapter also has some additional
GitHub and Git information.

One particularly great \href{https://try.github.io/}{tutorial} walks you
through the command line process for creating and using a git
repository. Even if you do not want to use Git via the command line, the
tutorial does an \emph{excellent} job of describing the logic and
sequence behind the Git workflow.

\hypertarget{advanced-git}{\chapter{Advanced Git}\label{advanced-git}}

GitHub has a number of tools available for managing multiple
contributors' work simultaneously. These tools will be useful for
collaborating with your teammates on the final project.

\section{Even More Git-lingo}\label{even-more-git-lingo}

Beyond the terms introduced in the previous chapter, there are a few
additional terms that are specific to collaborating that are helpful to
know:

\begin{itemize}
\tightlist
\item
  \textbf{Branch}: An identical copy of the repository that is distinct
  from the \texttt{master} copy.
\item
  \textbf{Checkout}: The act of switching to a new branch.
\item
  \textbf{Pull Request}: Request that the changes made on a branch be
  integrated into the \texttt{master} copy.
\end{itemize}

\section{Creating Branches}\label{creating-branches}

The logic behind branches is that they allow you to make modifications
to the content of the repository without impacting the content that is
on the \texttt{master} branch. Think of the \texttt{master} branch is
your production data - this is what you know is good and in working
order. If you need to experiment, say by adding new code or data
sources, you can do this on a branch without worrying about breaking
something in the production part of the repository.

To create a new branch, navigate to the repository in question on
GitHub.com. Just above the list of the repository's contents on the
lefthand side of the winodw is a button that will read ``Branch:
master''. If you pull the associated menu down, you have the ability to
create a new branch (by typing a name into the text field) or switch
between branches:

\includegraphics[width=1\linewidth]{images/branch1}

The image above shows this menu pulled down with the ficticious user
John Snow creating a new branch on his assignments repository named
\texttt{snowBranch}. Once the branch is created, you will automatically
be directed to the new branch's contents. These should look identical to
the \texttt{master} branch at this point because the branch creation
process generates a mirror image of \texttt{master}.

You can use the same pulldown menu to switch back to the \texttt{master}
branch if needed:

\includegraphics[width=1\linewidth]{images/branch2}

\subsection{Working with Branches}\label{working-with-branches}

Once your branch is created, you need to open up GitHub desktop and, if
you haven't already, clone the repository you created the branch in. If
you have already cloned the repository, you just need to \texttt{Sync}
it so that the branch information is downloaded to your local copy of
the repository.

Once you have updated or cloned your repository, it is time to
\textbf{checkout} the branch. This means to switch from the current
branch (by default, the \texttt{master} branch, to your new branch). In
GitHub Desktop, there is a button on the top toolbar that will say the
current branch name (by default, \texttt{master}). You can click on this
button to open a pulldown menu that will list all available branches:

\includegraphics[width=1\linewidth]{images/branch3}

Click on a branch to check it out. Once checked out, the files available
to your operating system will change to reflect the contents of that
branch!

It is important that you ensure that you are always intentionally
working on the correct branch. Any time you return to your computer to
continue working on a branch, open up GitHub Desktop and ensure that the
proper branch remains checked out.

Branches are used just like regular repos in Git. You can commit changes
to them and sync them with GitHub.com. I recommend commiting changes to
branches regularly and syncing them with the remote version of the
repository to ensure that your work is not lost.

\subsection{Opening Pull Requests}\label{opening-pull-requests}

When you have made changes to your branch and want to integrate them
into the \texttt{master}, production part of your repository, it is time
to open a \textbf{pull request}. Below, you will see that a directory
named \texttt{ExtraWork} has been added to the \texttt{SnowAssignments}
repository's \texttt{snowBranch}:

\includegraphics[width=1\linewidth]{images/branch4}

We have verified that the file is complete and ready for integration
into the \texttt{master} branch. To do this, we need to click on the
\texttt{New\ pull\ request} button just to the right of the
\texttt{Branch} button above your repository contents. Make sure that
you are opening the pull request on your branch and not on the
\texttt{master}!

\includegraphics[width=1\linewidth]{images/branch5}

The \textbf{pull request} page looks very similar to GitHub's
\textbf{Issue} feature - there is a place for a title (which will be
autofilled for you) and for describing the contents and signifiance of
your changes. You can optionally assign individual reviewers (such as
your final project team members). Once you are done, click the green
\texttt{Create\ pull\ request} button.

\subsection{Evaluating Pull Requests}\label{evaluating-pull-requests}

When a team member opens a \textbf{pull request}, you should see a
notification in your news feed on the main landing page when you log
into GitHub.com:

\includegraphics[width=1\linewidth]{images/branch6}

Clicking on that message (or, alternatively, selecting the
\texttt{Pull\ Requests} tab in any repository) will take you to a page
where you can evaluate changes that were made on your colleague's
branch:

\includegraphics[width=1\linewidth]{images/branch7}

Here you can: * view files that have been changed or added, * respond to
the pull request with a comment if you have follow-up questions, * view
the results of GitHub's conflict check, * and choose an outcome (either
merging - i.e.~accepting - the pull request or closing - i.e.~rejecting
- the pull request)

This is an integral step. It is part of the peer review process that
drives open-source software and is conducted in the same spirit of peer
review that academics use to evaluate publications. The goal here is
provide constructive feedback about proposed additions or changes. If
you choose to close (i.e.~reject) a pull request, give a detailed
explanation as to why you are doing so.

If you see that there are conflicts with the base (i.e. \texttt{master})
branch, please let Chris know immediately to problem solve before any
pull requests are accepted.

If you want to accept the changes, select the green
\texttt{Merge\ pull\ request} button. Chosing this button will open up a
space for you to add a commit message that corresponds with accepting
the pull request:

\includegraphics[width=1\linewidth]{images/branch8}

After filling out your commit message and selecting
\texttt{Confirm\ merge}, you have one final opportunity to either roll
back the changes (by chosing \texttt{Revert}) or make them permanent by
chosing \texttt{Delete\ branch}.

\section{Git Terminal}\label{git-terminal}

T

\bibliography{book.bib,packages.bib}


\end{document}
